{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba5173bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spektral in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (1.3.1)\n",
      "Requirement already satisfied: joblib in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (1.2.0)\n",
      "Requirement already satisfied: lxml in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (4.9.3)\n",
      "Requirement already satisfied: networkx in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (3.2.1)\n",
      "Requirement already satisfied: numpy in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (1.25.0)\n",
      "Requirement already satisfied: pandas in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (2.2.3)\n",
      "Requirement already satisfied: requests in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (1.1.3)\n",
      "Requirement already satisfied: scipy in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (1.11.3)\n",
      "Requirement already satisfied: tqdm in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (4.66.1)\n",
      "Requirement already satisfied: tensorflow-macos>=2.5.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral) (2.16.2)\n",
      "Requirement already satisfied: tensorflow==2.16.2 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow-macos>=2.5.0->spektral) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (4.25.6)\n",
      "Requirement already satisfied: setuptools in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from requests->spektral) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from requests->spektral) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from requests->spektral) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from requests->spektral) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from pandas->spektral) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from pandas->spektral) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from pandas->spektral) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from scikit-learn->spektral) (3.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.41.2)\n",
      "Requirement already satisfied: rich in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (2.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (3.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral) (0.1.2)\n",
      "Collecting git+https://github.com/danielegrattarola/spektral.git\n",
      "  Cloning https://github.com/danielegrattarola/spektral.git to /private/var/folders/7q/fws4rlfs7rv4sxqpn_xpmr6m0000gn/T/pip-req-build-kbxk1d8_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/danielegrattarola/spektral.git /private/var/folders/7q/fws4rlfs7rv4sxqpn_xpmr6m0000gn/T/pip-req-build-kbxk1d8_\n",
      "  Resolved https://github.com/danielegrattarola/spektral.git to commit a5fa5e38fca4eaca1e47ccfe1b00e0a61f64648b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (1.2.0)\n",
      "Requirement already satisfied: lxml in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (4.9.3)\n",
      "Requirement already satisfied: networkx in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (3.2.1)\n",
      "Requirement already satisfied: numpy in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (1.25.0)\n",
      "Requirement already satisfied: pandas in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (2.2.3)\n",
      "Requirement already satisfied: requests in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (1.1.3)\n",
      "Requirement already satisfied: scipy in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (1.11.3)\n",
      "Requirement already satisfied: tensorflow-macos>=2.5.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (2.16.2)\n",
      "Requirement already satisfied: tqdm in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from spektral==1.3.1) (4.66.1)\n",
      "Requirement already satisfied: tensorflow==2.16.2 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow-macos>=2.5.0->spektral==1.3.1) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (4.25.6)\n",
      "Requirement already satisfied: setuptools in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from requests->spektral==1.3.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from requests->spektral==1.3.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from requests->spektral==1.3.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from requests->spektral==1.3.1) (2023.7.22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from pandas->spektral==1.3.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from pandas->spektral==1.3.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from pandas->spektral==1.3.1) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from scikit-learn->spektral==1.3.1) (3.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.41.2)\n",
      "Requirement already satisfied: rich in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (3.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (2.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (3.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos>=2.5.0->spektral==1.3.1) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install spektral\n",
    "!pip install --upgrade git+https://github.com/danielegrattarola/spektral.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995c185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spektral\n",
    "from spektral.datasets import TUDataset\n",
    "from spektral.data import Dataset\n",
    "from spektral.layers import GCNConv, GlobalAvgPool, GlobalMaxPool, GlobalSumPool\n",
    "from spektral.data import DisjointLoader\n",
    "\n",
    "# reg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.sparse import SparseTensor\n",
    "\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353e74e",
   "metadata": {},
   "source": [
    "# Q1: Exploring and Visualizing the PROTEINS Dataset [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89359ecb",
   "metadata": {},
   "source": [
    "1. Dataset Inspection & Statistics\n",
    "\n",
    "○ a. Load the PROTEINS dataset using the provided code from the lecture.\n",
    "\n",
    "○ b. Print the total number of graphs, the number of node features per graph, and the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0ea443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded PROTEINS.\n",
      "Total graphs in PROTEINS: 1113\n",
      "Number of node features per graph: 4\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# load proteins dataset\n",
    "dataset = TUDataset(\"PROTEINS\")\n",
    "\n",
    "# print total n of graphs, n of node featrues per graph, and n of classes\n",
    "print(\"Total graphs in PROTEINS:\", len(dataset))\n",
    "print(\"Number of node features per graph:\", dataset.n_node_features)\n",
    "print(\"Number of classes:\", dataset.n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b3e42",
   "metadata": {},
   "source": [
    "2. Computing Graph Statistics\n",
    "\n",
    "○ a. Iterate over all graphs in the dataset to compute:\n",
    "\n",
    "    ■ The number of nodes per graph.\n",
    "\n",
    "    ■ The number of edges per graph (remember that for undirected graphs each edge is counted twice).\n",
    "\n",
    "    ■ The global label for each graph (convert from a one-hot vector to an integer).\n",
    "\n",
    "○ b. Store these statistics as NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e49d1",
   "metadata": {},
   "source": [
    "3. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec16cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty to store iterations\n",
    "num_nodes = []\n",
    "num_edges = []\n",
    "labels = []\n",
    "\n",
    "# iterate over  1113 graphs\n",
    "for graph in dataset:\n",
    "    # number of nodes per graph\n",
    "    num_nodes.append(graph.n_nodes)\n",
    "\n",
    "    # number of edges per graph/avoid double counting edges\n",
    "    num_edges.append(graph.n_edges // 2)\n",
    "    \n",
    "    # global label for each graph (convert from a one-hot vector to an integer)\n",
    "    labels.append(np.argmax(graph.y))\n",
    "\n",
    "# store statistics as np arrays\n",
    "num_nodes = np.array(num_nodes)\n",
    "num_edges = np.array(num_edges)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e2bed",
   "metadata": {},
   "source": [
    "○ a. Plot a histogram of the number of nodes per graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f6a5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(num_nodes, bins=60, color='green')\n",
    "plt.title('histogram of the number of nodes per graph')\n",
    "plt.xlabel('number of nodes')\n",
    "plt.ylabel('graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ad1115",
   "metadata": {},
   "source": [
    "○ b. Plot a histogram of the number of edges per graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399a6b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(num_edges, bins=60, color='green')\n",
    "plt.title('histogram of the number of edges per graph ')\n",
    "plt.xlabel('number of edges')\n",
    "plt.ylabel('graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3f955",
   "metadata": {},
   "source": [
    "○ c. Create a bar plot to show the distribution of graph labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c17aba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(np.unique(labels), np.bincount(labels), color='green')\n",
    "plt.title('distribution of graph labels')\n",
    "plt.xticks(np.arange(0,2,1))\n",
    "plt.xlabel('graph labels')\n",
    "plt.ylabel('graphs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256685d",
   "metadata": {},
   "source": [
    "Discuss:\n",
    "\n",
    "● How do the distributions of nodes and edges inform you about the complexity of the dataset?\n",
    "\n",
    "● What observations can you make about the distribution of graph labels and how might these affect model training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0a561",
   "metadata": {},
   "source": [
    "The distributions of nodes and edges are both right skewed, with most graphs having between 0-100 nodes and 0-200 edges. This tells us this is a very complex dataset. \n",
    "\n",
    "Regarding graph labels, there is a class imbalance with more graphs having a label of 0 than 1. This imbalance could cause bias towards the majority class (0) and lead to poor performance and capturing of patterns/complexities in the minority class (1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc6098",
   "metadata": {},
   "source": [
    "# Q2: Building and Evaluating a Graph Convolutional Network (GCN) [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ce8bd",
   "metadata": {},
   "source": [
    "1. Dataset Preparation\n",
    "\n",
    "○ Split the dataset into training and testing sets (80-20% split) by implementing a custom SubsetDataset wrapper using the provided code from the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7895fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training graphs: 890\n",
      "Test graphs: 223\n"
     ]
    }
   ],
   "source": [
    "# Split indices for training and test sets\n",
    "indices = np.arange(len(dataset))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a custom Dataset wrapper to hold a list of graphs\n",
    "class SubsetDataset(Dataset):\n",
    "    def __init__(self, graphs, **kwargs):\n",
    "        self._graphs = graphs\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        return self._graphs\n",
    "\n",
    "# Create training and test datasets using the wrapper\n",
    "train_graphs = [dataset[i] for i in train_idx]\n",
    "test_graphs = [dataset[i] for i in test_idx]\n",
    "\n",
    "train_dataset = SubsetDataset(train_graphs)\n",
    "test_dataset = SubsetDataset(test_graphs)\n",
    "\n",
    "print(\"Training graphs:\", len(train_dataset))\n",
    "print(\"Test graphs:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15191732",
   "metadata": {},
   "source": [
    "2. Model Construction\n",
    "\n",
    "○ a. Build a GCN model using TensorFlow and Spektral:\n",
    "\n",
    "    ■ Define the inputs for disjoint mode (node features, adjacency matrix, and graph indices).\n",
    "\n",
    "    ■ Create two GCN layers (you may use a custom GCN layer if desired) followed by a global pooling layer (e.g., GlobalAvgPool).\n",
    "\n",
    "    ■ Add a Dense output layer with softmax activation for classification.\n",
    "\n",
    "○ b. Compile the model using the Adam optimizer and categorical crossentropy\n",
    "loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d5441ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs for disjoint mode:\n",
    "# node features; features of nodes in each graph\n",
    "x_in = Input(shape=(dataset.n_node_features,), name='node_features')\n",
    "\n",
    "# adj matrix; connections between nodes\n",
    "a_in = Input(shape=(None,), sparse=True, name='adjacency_matrix')\n",
    "\n",
    "# graph indices for handling multiple graphs in a batch\n",
    "i_in = Input(shape=(), name='graph_index', dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24412b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGCNConv(GCNConv):\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Ignore mask propagation: always return None\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # Remove mask and training kwargs if present:\n",
    "        kwargs.pop('mask', None)\n",
    "        kwargs.pop('training', None)\n",
    "        return super().call(inputs, **kwargs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape is a tuple: (x_shape, a_shape)\n",
    "        # x_shape: (num_nodes, n_features) → output: (num_nodes, channels)\n",
    "        return (input_shape[0][0], self.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea34c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your custom convolution layers instead of the standard GCNConv:\n",
    "x = MyGCNConv(32, activation='relu')([x_in, a_in])\n",
    "x = MyGCNConv(32, activation='relu')([x, a_in])\n",
    "\n",
    "# aggregate node features into single representation per graph \n",
    "pool = GlobalAvgPool()([x, i_in])\n",
    "\n",
    "# output layer for clas\n",
    "output = Dense(dataset.n_labels, activation='softmax')(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b05bc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ node_features       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ adjacency_matrix    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ node_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyGCNConv</span>)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ my_gcn_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyGCNConv</span>)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ graph_index         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_avg_pool     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ my_gcn_conv_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAvgPool</span>)     │                   │            │ graph_index[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │ global_avg_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ node_features       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ adjacency_matrix    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m160\u001b[0m │ node_features[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMyGCNConv\u001b[0m)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,056\u001b[0m │ my_gcn_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMyGCNConv\u001b[0m)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ graph_index         │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_avg_pool     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ my_gcn_conv_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAvgPool\u001b[0m)     │                   │            │ graph_index[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m66\u001b[0m │ global_avg_pool[\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,282</span> (5.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,282\u001b[0m (5.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,282</span> (5.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,282\u001b[0m (5.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compile model\n",
    "model = Model(inputs=[x_in, a_in, i_in], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a348ba9",
   "metadata": {},
   "source": [
    "3. Training & Evaluation\n",
    "\n",
    "○ a. Train the model for 20 epochs using DisjointLoaders for both the training and test sets.\n",
    "\n",
    "○ b. Plot the training and test loss as well as the accuracy curves over the epochs.\n",
    "\n",
    "○ c. Evaluate the model on the test set and report the final test loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca35462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can create DisjointLoaders without the 'signature' error:\n",
    "from spektral.data.loaders import DisjointLoader\n",
    "\n",
    "train_loader = DisjointLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DisjointLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1d1f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['node_features', 'adjacency_matrix', 'graph_index']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/28\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3871 - loss: 8.6479    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'SubsetDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4264 - loss: 6.5935 - val_accuracy: 0.5785 - val_loss: 0.8206\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6536 - loss: 0.8079 - val_accuracy: 0.6323 - val_loss: 0.8055\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6829 - loss: 0.6487 - val_accuracy: 0.6009 - val_loss: 0.7558\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.6527 - val_accuracy: 0.6502 - val_loss: 0.7368\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6635 - loss: 0.6792 - val_accuracy: 0.6233 - val_loss: 0.7221\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6723 - loss: 0.6543 - val_accuracy: 0.5785 - val_loss: 0.7646\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6905 - loss: 0.6201 - val_accuracy: 0.6323 - val_loss: 0.7280\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6814 - loss: 0.6203 - val_accuracy: 0.6323 - val_loss: 0.7043\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6937 - loss: 0.5885 - val_accuracy: 0.5516 - val_loss: 0.7610\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6439 - loss: 0.6401 - val_accuracy: 0.6323 - val_loss: 0.7102\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6809 - loss: 0.5977 - val_accuracy: 0.5964 - val_loss: 0.7303\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6893 - loss: 0.6147 - val_accuracy: 0.6278 - val_loss: 0.6894\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6490 - loss: 0.6387 - val_accuracy: 0.6188 - val_loss: 0.6889\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6815 - loss: 0.5997 - val_accuracy: 0.6502 - val_loss: 0.7253\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6585 - loss: 0.6491 - val_accuracy: 0.6099 - val_loss: 0.8794\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6109 - loss: 0.6997 - val_accuracy: 0.6323 - val_loss: 0.7084\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.6091 - val_accuracy: 0.6054 - val_loss: 0.6904\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6667 - loss: 0.6221 - val_accuracy: 0.6278 - val_loss: 0.6880\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6445 - loss: 0.6424 - val_accuracy: 0.6233 - val_loss: 0.6950\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6573 - loss: 0.6271 - val_accuracy: 0.6233 - val_loss: 0.7921\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_loader.load(),\n",
    "    steps_per_epoch=train_loader.steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=test_loader.load(),\n",
    "    validation_steps=test_loader.steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8026530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], marker='o', label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], marker='o', label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (categorical crossentropy)')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], marker='o', label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], marker='o', label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1c0afa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6302 - loss: 0.7694 \n",
      "final testing loss: 0.792084813117981\n",
      "final testing accuracy: 0.6233183741569519\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(\n",
    "    test_loader.load(),\n",
    "    steps=test_loader.steps_per_epoch\n",
    ")\n",
    "\n",
    "print(f\"final testing loss: {test_loss}\")\n",
    "print(f\"final testing accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584ae96",
   "metadata": {},
   "source": [
    "The model did face challenges involving overfitting as well as low accuracies. A technique could be learning rate schedules to help the optimizer converge more effectively or even early stopping. Regularization can be used to help reduce overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1605a78",
   "metadata": {},
   "source": [
    "# Q3: Hyperparameter Tuning for GCN Models on a Sampled PROTEINS Subset [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f1f6a",
   "metadata": {},
   "source": [
    "1. Dataset Subsampling & Preparation\n",
    "\n",
    "○ Split this subset into training and test sets (80-20% split) and set up DisjointLoaders for each.\n",
    "\n",
    "○ Randomly sample 300 graphs for hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0634d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_graphs = np.random.choice(train_graphs, 300, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad66c92",
   "metadata": {},
   "source": [
    "2. Model Building with Hyperparameters\n",
    "\n",
    "○ Define a function to build a GCN model that accepts hyperparameters for:\n",
    "\n",
    "    ■ The number of GCN layers.\n",
    "    ■ Dropout rate (optional dropout after each layer).\n",
    "    ■ The choice of pooling layer (e.g., GlobalAvgPool, GlobalSumPool, GlobalMaxPool).\n",
    "    ■ Learning rate.\n",
    "    \n",
    "○ Compile the model with the appropriate loss and optimizer settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e0d55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters: \n",
    "'''The number of GCN layers.\n",
    "■ Dropout rate (optional dropout after each layer).\n",
    "■ The choice of pooling layer (e.g., GlobalAvgPool, GlobalSumPool,\n",
    "GlobalMaxPool).\n",
    "■ Learning rate.\n",
    "'''\n",
    "\n",
    "# returns compiled GCN model\n",
    "def build_gcn_model(num_layers, dropout_rate, pooling_type, learning_rate, input_shape, num_classes):\n",
    "    # input layer\n",
    "    x_in = Input(shape=(input_shape,), name='node_features')\n",
    "    # adjacency matrix; connections between nodes\n",
    "    a_in = Input(shape=(None,), sparse=True, name='adjacency_matrix')\n",
    "    # graph indices for handling multiple graphs in a batch\n",
    "    i_in = Input(shape=(), name='graph_index', dtype=\"int32\")\n",
    "    \n",
    "\n",
    "    # GCN layers\n",
    "    x = x_in\n",
    "    for _ in range(num_layers):\n",
    "        x = MyGCNConv(32, activation='relu')([x, a_in]) \n",
    "         # Dropout after each GCN layer\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # pooling\n",
    "    if pooling_type == 'avg':\n",
    "        x = GlobalAvgPool()([x, i_in])  \n",
    "    elif pooling_type == 'sum':\n",
    "        x = GlobalSumPool()([x, i_in]) \n",
    "    elif pooling_type == 'max':\n",
    "        x = GlobalMaxPool()([x, i_in])  \n",
    "    \n",
    "#     # fully connected layers\n",
    "#     x = Dense(64, activation='relu')(x) \n",
    "#     x = Dropout(dropout_rate)(x) \n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # model\n",
    "    model = Model(inputs=[x_in, a_in, i_in], outputs=output)\n",
    "\n",
    "    # complie\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef149fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ node_features       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ adjacency_matrix    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ node_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyGCNConv</span>)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ my_gcn_conv_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyGCNConv</span>)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ my_gcn_conv_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyGCNConv</span>)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ my_gcn_conv_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ graph_index         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_avg_pool_1   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAvgPool</span>)     │                   │            │ graph_index[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │ global_avg_pool_… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ node_features       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ adjacency_matrix    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m160\u001b[0m │ node_features[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMyGCNConv\u001b[0m)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ my_gcn_conv_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,056\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mMyGCNConv\u001b[0m)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ my_gcn_conv_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_gcn_conv_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,056\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMyGCNConv\u001b[0m)         │                   │            │ adjacency_matrix… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ my_gcn_conv_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ graph_index         │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_avg_pool_1   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mGlobalAvgPool\u001b[0m)     │                   │            │ graph_index[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m66\u001b[0m │ global_avg_pool_… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,338</span> (9.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,338\u001b[0m (9.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,338</span> (9.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,338\u001b[0m (9.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_layers = 3\n",
    "dropout_rate = 0.5\n",
    "pooling_type = 'avg' \n",
    "learning_rate = 0.001\n",
    "input_shape = 4\n",
    "num_classes = 2\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_gcn_model(num_layers, dropout_rate, pooling_type, learning_rate, input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50460085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4555 - loss: 32.2834 - val_accuracy: 0.5919 - val_loss: 13.2130\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5138 - loss: 7.8316 - val_accuracy: 0.5874 - val_loss: 6.9762\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5542 - loss: 5.7518 - val_accuracy: 0.5874 - val_loss: 4.3575\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5430 - loss: 4.4568 - val_accuracy: 0.5874 - val_loss: 4.4325\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5924 - loss: 3.0941 - val_accuracy: 0.5874 - val_loss: 3.1134\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5410 - loss: 3.2969 - val_accuracy: 0.5919 - val_loss: 2.6502\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5185 - loss: 3.2382 - val_accuracy: 0.5919 - val_loss: 1.6262\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5415 - loss: 2.0231 - val_accuracy: 0.5919 - val_loss: 1.3652\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5525 - loss: 2.1320 - val_accuracy: 0.5919 - val_loss: 1.5095\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5747 - loss: 1.6820 - val_accuracy: 0.5919 - val_loss: 1.1386\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5309 - loss: 1.6809 - val_accuracy: 0.6233 - val_loss: 0.7199\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5331 - loss: 1.4447 - val_accuracy: 0.5919 - val_loss: 0.8667\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5353 - loss: 1.4779 - val_accuracy: 0.5919 - val_loss: 0.8674\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5330 - loss: 1.3371 - val_accuracy: 0.6099 - val_loss: 0.6792\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6015 - loss: 1.1076 - val_accuracy: 0.6099 - val_loss: 0.6633\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5575 - loss: 1.1203 - val_accuracy: 0.6054 - val_loss: 0.6745\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5543 - loss: 1.0191 - val_accuracy: 0.5964 - val_loss: 0.6998\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5381 - loss: 1.0657 - val_accuracy: 0.5919 - val_loss: 0.7027\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5907 - loss: 0.9385 - val_accuracy: 0.6009 - val_loss: 0.6568\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5509 - loss: 0.8933 - val_accuracy: 0.5919 - val_loss: 0.6857\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5912 - loss: 0.6924 \n",
      "test Loss: 0.792\n",
      "Test Accuracy: 0.623\n"
     ]
    }
   ],
   "source": [
    "history_hp = model.fit(\n",
    "    train_loader.load(),\n",
    "    steps_per_epoch=train_loader.steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=test_loader.load(),\n",
    "    validation_steps=test_loader.steps_per_epoch\n",
    ")\n",
    "\n",
    "\n",
    "hp_test_loss, hp_test_accuracy = model.evaluate(\n",
    "    test_loader.load(),\n",
    "    steps=test_loader.steps_per_epoch\n",
    ")\n",
    "\n",
    "print(f\"test Loss: {test_loss:.3f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12559541",
   "metadata": {},
   "source": [
    "3. Grid Search & Visualization\n",
    "\n",
    "○ Define a grid of hyperparameter combinations:\n",
    "\n",
    "    ■ Number of layers: [1, 2, 3]\n",
    "    \n",
    "    ■ Dropout rates: [0.1, 0.2, 0.3]\n",
    "    \n",
    "    ■ Learning rates: [0.001, 0.0005, 0.0001]\n",
    "    \n",
    "    ■ Pooling variants: GlobalAvgPool, GlobalSumPool, GlobalMaxPool\n",
    "    \n",
    "○ Visualize the distribution of test accuracies for each hyperparameter using box\n",
    "plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "521ee206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparam grid\n",
    "num_layers = [1, 2, 3]\n",
    "dropout_rates = [0.1, 0.2, 0.3]\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "pooling_var = ['avg','sum','max']\n",
    "\n",
    "param_grid = list(product(num_layers, dropout_rates, learning_rates, pooling_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10a1c085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with: layers = 1, dropout = 0.1, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5555 - loss: 1.5324 - val_accuracy: 0.6143 - val_loss: 0.7149\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6099 - loss: 0.7736 - val_accuracy: 0.6368 - val_loss: 0.7159\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5758 - loss: 0.8225 - val_accuracy: 0.6143 - val_loss: 0.6955\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5884 - loss: 0.7419 - val_accuracy: 0.6054 - val_loss: 0.7054\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5399 - loss: 0.7756 - val_accuracy: 0.6054 - val_loss: 0.6829\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5640 - loss: 0.7631 - val_accuracy: 0.6188 - val_loss: 0.6791\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5393 - loss: 0.7837 - val_accuracy: 0.5874 - val_loss: 0.6945\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5834 - loss: 0.7813 - val_accuracy: 0.6054 - val_loss: 0.6800\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5546 - loss: 0.7393 - val_accuracy: 0.6188 - val_loss: 0.6742\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5680 - loss: 0.7306 - val_accuracy: 0.6009 - val_loss: 0.6809\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6117 - loss: 0.7447 - val_accuracy: 0.6099 - val_loss: 0.6824\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6208 - loss: 0.7192 - val_accuracy: 0.6099 - val_loss: 0.6776\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6066 - loss: 0.7229 - val_accuracy: 0.6368 - val_loss: 0.6765\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6035 - loss: 0.7409 - val_accuracy: 0.6413 - val_loss: 0.6752\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6216 - loss: 0.7212 - val_accuracy: 0.6099 - val_loss: 0.6753\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6152 - loss: 0.7239 - val_accuracy: 0.6054 - val_loss: 0.6944\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6127 - loss: 0.7159 - val_accuracy: 0.6054 - val_loss: 0.6851\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6015 - loss: 0.7139 - val_accuracy: 0.6592 - val_loss: 0.6768\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6351 - loss: 0.6639 - val_accuracy: 0.6368 - val_loss: 0.6763\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6240 - loss: 0.7144 - val_accuracy: 0.6009 - val_loss: 0.7077\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6060 - loss: 0.6968 \n",
      "Training model with: layers = 1, dropout = 0.1, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4036 - loss: 133.1885 - val_accuracy: 0.5874 - val_loss: 17.7448\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6148 - loss: 18.4337 - val_accuracy: 0.5471 - val_loss: 5.7416\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5299 - loss: 10.2774 - val_accuracy: 0.6143 - val_loss: 7.2272\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5505 - loss: 8.6056 - val_accuracy: 0.5830 - val_loss: 4.8779\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5606 - loss: 7.5335 - val_accuracy: 0.5964 - val_loss: 5.5164\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5593 - loss: 7.4699 - val_accuracy: 0.5919 - val_loss: 4.7339\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5851 - loss: 6.6572 - val_accuracy: 0.5516 - val_loss: 3.7019\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5602 - loss: 6.8565 - val_accuracy: 0.5874 - val_loss: 4.1434\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5571 - loss: 7.0261 - val_accuracy: 0.5695 - val_loss: 5.5734\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5732 - loss: 7.1027 - val_accuracy: 0.5830 - val_loss: 4.8087\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5783 - loss: 6.1750 - val_accuracy: 0.5785 - val_loss: 4.4255\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5799 - loss: 6.5384 - val_accuracy: 0.5830 - val_loss: 3.0081\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5731 - loss: 6.6703 - val_accuracy: 0.5830 - val_loss: 2.8914\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6097 - loss: 5.0135 - val_accuracy: 0.5516 - val_loss: 3.0769\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5570 - loss: 7.5938 - val_accuracy: 0.5785 - val_loss: 2.6713\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5928 - loss: 6.1201 - val_accuracy: 0.5964 - val_loss: 2.5757\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5547 - loss: 6.4873 - val_accuracy: 0.5291 - val_loss: 3.2544\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5859 - loss: 5.5538 - val_accuracy: 0.5919 - val_loss: 3.0155\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5650 - loss: 6.6339 - val_accuracy: 0.5830 - val_loss: 2.2013\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5914 - loss: 5.2889 - val_accuracy: 0.5830 - val_loss: 2.4190\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5462 - loss: 2.5104 \n",
      "Training model with: layers = 1, dropout = 0.1, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4160 - loss: 10.7376 - val_accuracy: 0.4081 - val_loss: 4.5548\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4944 - loss: 1.4281 - val_accuracy: 0.5785 - val_loss: 2.1170\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5575 - loss: 0.7674 - val_accuracy: 0.5650 - val_loss: 2.0890\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5831 - loss: 1.3518 - val_accuracy: 0.5202 - val_loss: 1.9142\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5586 - loss: 0.8821 - val_accuracy: 0.5785 - val_loss: 1.6099\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5888 - loss: 0.7265 - val_accuracy: 0.5785 - val_loss: 1.3899\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5876 - loss: 0.7383 - val_accuracy: 0.5785 - val_loss: 1.1885\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5899 - loss: 0.7502 - val_accuracy: 0.5919 - val_loss: 1.0359\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5699 - loss: 0.8084 - val_accuracy: 0.5830 - val_loss: 0.8896\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6204 - loss: 0.7565 - val_accuracy: 0.6054 - val_loss: 0.7331\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6148 - loss: 0.7147 - val_accuracy: 0.6054 - val_loss: 0.7061\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6222 - loss: 0.7087 - val_accuracy: 0.5830 - val_loss: 0.7080\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6094 - loss: 0.6868 - val_accuracy: 0.6009 - val_loss: 0.7161\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6092 - loss: 0.7486 - val_accuracy: 0.6054 - val_loss: 0.7128\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6219 - loss: 0.7184 - val_accuracy: 0.5919 - val_loss: 0.7045\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6105 - loss: 0.7070 - val_accuracy: 0.6143 - val_loss: 0.6981\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6104 - loss: 0.7174 - val_accuracy: 0.5964 - val_loss: 0.7117\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6420 - loss: 0.6963 - val_accuracy: 0.5919 - val_loss: 0.6966\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6433 - loss: 0.6776 - val_accuracy: 0.5874 - val_loss: 0.6977\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6357 - loss: 0.6853 - val_accuracy: 0.5785 - val_loss: 0.7128\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 0.7047 \n",
      "Training model with: layers = 1, dropout = 0.1, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3829 - loss: 6.3948 - val_accuracy: 0.4081 - val_loss: 1.5156\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4501 - loss: 1.0790 - val_accuracy: 0.5964 - val_loss: 0.7103\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6012 - loss: 0.7482 - val_accuracy: 0.6143 - val_loss: 0.6676\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5817 - loss: 0.7400 - val_accuracy: 0.6188 - val_loss: 0.6699\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 0.6980 - val_accuracy: 0.6188 - val_loss: 0.6662\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5889 - loss: 0.6953 - val_accuracy: 0.6143 - val_loss: 0.6686\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6338 - loss: 0.6810 - val_accuracy: 0.6054 - val_loss: 0.6718\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5142 - loss: 0.7480 - val_accuracy: 0.5964 - val_loss: 0.6771\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5968 - loss: 0.6894 - val_accuracy: 0.6099 - val_loss: 0.6694\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6306 - loss: 0.6826 - val_accuracy: 0.6009 - val_loss: 0.6772\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6061 - loss: 0.7355 - val_accuracy: 0.6502 - val_loss: 0.6738\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6331 - loss: 0.6754 - val_accuracy: 0.6054 - val_loss: 0.6706\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6106 - loss: 0.7430 - val_accuracy: 0.6099 - val_loss: 0.6712\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6400 - loss: 0.6887 - val_accuracy: 0.6099 - val_loss: 0.6720\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6293 - loss: 0.6954 - val_accuracy: 0.6278 - val_loss: 0.6731\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5860 - loss: 0.7415 - val_accuracy: 0.6457 - val_loss: 0.6787\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6020 - loss: 0.6950 - val_accuracy: 0.6233 - val_loss: 0.6820\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6136 - loss: 0.6937 - val_accuracy: 0.6502 - val_loss: 0.6792\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5915 - loss: 0.7081 - val_accuracy: 0.6368 - val_loss: 0.6848\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6377 - loss: 0.6659 - val_accuracy: 0.6547 - val_loss: 0.6804\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6833 - loss: 0.6755 \n",
      "Training model with: layers = 1, dropout = 0.1, lr = 0.0005, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3836 - loss: 182.4017 - val_accuracy: 0.5919 - val_loss: 26.4951\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6071 - loss: 21.5779 - val_accuracy: 0.4215 - val_loss: 5.9689\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5327 - loss: 10.7967 - val_accuracy: 0.6099 - val_loss: 2.0487\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5619 - loss: 7.4876 - val_accuracy: 0.5919 - val_loss: 4.9975\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5936 - loss: 6.9311 - val_accuracy: 0.5919 - val_loss: 4.9218\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5671 - loss: 6.8718 - val_accuracy: 0.5919 - val_loss: 5.1294\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5674 - loss: 7.9639 - val_accuracy: 0.6099 - val_loss: 2.7273\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6132 - loss: 6.9025 - val_accuracy: 0.5964 - val_loss: 4.0222\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6108 - loss: 7.4826 - val_accuracy: 0.5919 - val_loss: 5.9831\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5799 - loss: 7.4819 - val_accuracy: 0.6413 - val_loss: 2.6988\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5765 - loss: 7.3937 - val_accuracy: 0.6413 - val_loss: 2.5276\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5806 - loss: 6.4619 - val_accuracy: 0.6188 - val_loss: 3.8481\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5947 - loss: 6.7908 - val_accuracy: 0.6323 - val_loss: 1.9696\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6256 - loss: 7.0128 - val_accuracy: 0.6368 - val_loss: 2.5436\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5428 - loss: 7.8501 - val_accuracy: 0.6368 - val_loss: 2.7155\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5668 - loss: 7.4829 - val_accuracy: 0.6502 - val_loss: 2.8291\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6030 - loss: 6.9064 - val_accuracy: 0.6323 - val_loss: 3.1448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5682 - loss: 6.9248 - val_accuracy: 0.6413 - val_loss: 2.6582\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5697 - loss: 7.8185 - val_accuracy: 0.6054 - val_loss: 4.1443\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6386 - loss: 5.0375 - val_accuracy: 0.6502 - val_loss: 3.2143\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6621 - loss: 2.8751 \n",
      "Training model with: layers = 1, dropout = 0.1, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5811 - loss: 2.0583 - val_accuracy: 0.5830 - val_loss: 1.7493\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5618 - loss: 0.8846 - val_accuracy: 0.5830 - val_loss: 1.4852\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6048 - loss: 0.7447 - val_accuracy: 0.5740 - val_loss: 1.3481\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6185 - loss: 0.8170 - val_accuracy: 0.6009 - val_loss: 1.0644\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6201 - loss: 0.8372 - val_accuracy: 0.5605 - val_loss: 0.8923\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5861 - loss: 0.8896 - val_accuracy: 0.5964 - val_loss: 0.6840\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6443 - loss: 0.7778 - val_accuracy: 0.6099 - val_loss: 0.6832\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6068 - loss: 0.7526 - val_accuracy: 0.6099 - val_loss: 0.6694\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6670 - loss: 0.6689 - val_accuracy: 0.5650 - val_loss: 0.6959\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6599 - loss: 0.6935 - val_accuracy: 0.6099 - val_loss: 0.6801\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6379 - loss: 0.7243 - val_accuracy: 0.5830 - val_loss: 0.6864\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6433 - loss: 0.7045 - val_accuracy: 0.6278 - val_loss: 0.6841\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6141 - loss: 0.7218 - val_accuracy: 0.5874 - val_loss: 0.7094\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6354 - loss: 0.7209 - val_accuracy: 0.6413 - val_loss: 0.6563\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6152 - loss: 0.7540 - val_accuracy: 0.6368 - val_loss: 0.6552\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6762 - loss: 0.6729 - val_accuracy: 0.6233 - val_loss: 0.6919\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6173 - loss: 0.7340 - val_accuracy: 0.4978 - val_loss: 0.7746\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6399 - loss: 0.7055 - val_accuracy: 0.6368 - val_loss: 0.6736\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6098 - loss: 0.7795 - val_accuracy: 0.5919 - val_loss: 0.7027\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6366 - loss: 0.7671 - val_accuracy: 0.6413 - val_loss: 0.6541\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6591 - loss: 0.6515 \n",
      "Training model with: layers = 1, dropout = 0.1, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5816 - loss: 0.6982 - val_accuracy: 0.6278 - val_loss: 0.6649\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6421 - loss: 0.6479 - val_accuracy: 0.6323 - val_loss: 0.6687\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 0.6419 - val_accuracy: 0.6233 - val_loss: 0.6757\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6245 - loss: 0.6913 - val_accuracy: 0.6323 - val_loss: 0.6740\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6470 - loss: 0.6488 - val_accuracy: 0.6323 - val_loss: 0.6772\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6474 - loss: 0.6601 - val_accuracy: 0.6368 - val_loss: 0.6795\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6535 - loss: 0.6249 - val_accuracy: 0.6502 - val_loss: 0.6840\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6719 - loss: 0.6262 - val_accuracy: 0.6143 - val_loss: 0.6941\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.6312 - val_accuracy: 0.6547 - val_loss: 0.6896\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.6291 - val_accuracy: 0.6547 - val_loss: 0.6863\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 0.6369 - val_accuracy: 0.6682 - val_loss: 0.6876\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6712 - loss: 0.6303 - val_accuracy: 0.6457 - val_loss: 0.6875\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6406 - loss: 0.6467 - val_accuracy: 0.6143 - val_loss: 0.7161\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 0.6496 - val_accuracy: 0.6457 - val_loss: 0.6861\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6217 - loss: 0.6487 - val_accuracy: 0.6413 - val_loss: 0.6871\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6966 - loss: 0.6197 - val_accuracy: 0.6637 - val_loss: 0.6866\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6763 - loss: 0.6113 - val_accuracy: 0.6413 - val_loss: 0.7017\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6720 - loss: 0.6339 - val_accuracy: 0.6502 - val_loss: 0.6961\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6745 - loss: 0.6287 - val_accuracy: 0.6278 - val_loss: 0.6897\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6644 - loss: 0.6308 - val_accuracy: 0.6413 - val_loss: 0.6970\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6772 - loss: 0.6892 \n",
      "Training model with: layers = 1, dropout = 0.1, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6132 - loss: 186.7010 - val_accuracy: 0.5919 - val_loss: 146.4382\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6150 - loss: 110.0927 - val_accuracy: 0.5919 - val_loss: 61.3695\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5950 - loss: 38.9684 - val_accuracy: 0.6278 - val_loss: 4.9440\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5557 - loss: 8.5858 - val_accuracy: 0.6278 - val_loss: 5.0031\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5540 - loss: 5.4379 - val_accuracy: 0.6099 - val_loss: 5.5503\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5681 - loss: 5.9973 - val_accuracy: 0.6233 - val_loss: 2.7439\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5353 - loss: 5.7944 - val_accuracy: 0.6188 - val_loss: 3.2097\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5747 - loss: 4.9952 - val_accuracy: 0.6188 - val_loss: 2.8224\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5793 - loss: 4.8530 - val_accuracy: 0.6009 - val_loss: 4.6810\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5894 - loss: 5.5209 - val_accuracy: 0.6054 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5825 - loss: 4.5872 - val_accuracy: 0.6009 - val_loss: 2.9261\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5927 - loss: 4.9676 - val_accuracy: 0.5964 - val_loss: 4.2100\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6065 - loss: 4.3883 - val_accuracy: 0.5919 - val_loss: 1.6483\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5689 - loss: 5.1495 - val_accuracy: 0.6009 - val_loss: 1.4698\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5837 - loss: 4.3294 - val_accuracy: 0.6009 - val_loss: 1.9596\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5977 - loss: 4.7340 - val_accuracy: 0.5964 - val_loss: 3.8196\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5710 - loss: 4.3186 - val_accuracy: 0.6143 - val_loss: 1.6260\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5653 - loss: 5.0064 - val_accuracy: 0.6009 - val_loss: 2.7603\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5501 - loss: 4.2566 - val_accuracy: 0.6143 - val_loss: 2.3668\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6062 - loss: 4.2373 - val_accuracy: 0.5919 - val_loss: 3.4577\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5868 - loss: 4.1659 \n",
      "Training model with: layers = 1, dropout = 0.1, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5552 - loss: 2.6582 - val_accuracy: 0.6099 - val_loss: 0.8623\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5703 - loss: 0.8344 - val_accuracy: 0.5964 - val_loss: 0.7039\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5912 - loss: 0.8183 - val_accuracy: 0.6323 - val_loss: 0.6945\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.8155 - val_accuracy: 0.6233 - val_loss: 0.6972\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6394 - loss: 0.8102 - val_accuracy: 0.6054 - val_loss: 0.6999\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6199 - loss: 0.7166 - val_accuracy: 0.6143 - val_loss: 0.6847\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5936 - loss: 0.7797 - val_accuracy: 0.6188 - val_loss: 0.6784\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6167 - loss: 0.7440 - val_accuracy: 0.6143 - val_loss: 0.6796\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6224 - loss: 0.7134 - val_accuracy: 0.6143 - val_loss: 0.6668\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 0.7669 - val_accuracy: 0.6009 - val_loss: 0.6911\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6110 - loss: 0.8171 - val_accuracy: 0.6054 - val_loss: 0.6811\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6277 - loss: 0.7543 - val_accuracy: 0.6278 - val_loss: 0.6701\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6227 - loss: 0.7977 - val_accuracy: 0.6233 - val_loss: 0.6816\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 0.8155 - val_accuracy: 0.6188 - val_loss: 0.6919\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5991 - loss: 0.8180 - val_accuracy: 0.6323 - val_loss: 0.6659\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6464 - loss: 0.8021 - val_accuracy: 0.6323 - val_loss: 0.6589\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6318 - loss: 0.7763 - val_accuracy: 0.6637 - val_loss: 0.6840\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6416 - loss: 0.7008 - val_accuracy: 0.6323 - val_loss: 0.6730\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 0.7393 - val_accuracy: 0.6368 - val_loss: 0.6767\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6474 - loss: 0.6941 - val_accuracy: 0.6278 - val_loss: 0.7455\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.7421 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4197 - loss: 6.8222 - val_accuracy: 0.4036 - val_loss: 1.0880\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5203 - loss: 1.0413 - val_accuracy: 0.6143 - val_loss: 0.7100\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5390 - loss: 1.0077 - val_accuracy: 0.6233 - val_loss: 0.6869\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5585 - loss: 0.9106 - val_accuracy: 0.6278 - val_loss: 0.6774\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5482 - loss: 0.9417 - val_accuracy: 0.6233 - val_loss: 0.6732\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5857 - loss: 0.8458 - val_accuracy: 0.6278 - val_loss: 0.6693\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5099 - loss: 0.9894 - val_accuracy: 0.6009 - val_loss: 0.6792\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6046 - loss: 0.8184 - val_accuracy: 0.5964 - val_loss: 0.6816\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5661 - loss: 0.8867 - val_accuracy: 0.5964 - val_loss: 0.6796\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5826 - loss: 0.9375 - val_accuracy: 0.6009 - val_loss: 0.6755\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5548 - loss: 0.9741 - val_accuracy: 0.5964 - val_loss: 0.7077\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5461 - loss: 0.8799 - val_accuracy: 0.5919 - val_loss: 0.7174\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5681 - loss: 0.9067 - val_accuracy: 0.6054 - val_loss: 0.6861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5199 - loss: 1.0324 - val_accuracy: 0.5964 - val_loss: 0.7073\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5463 - loss: 0.8810 - val_accuracy: 0.6054 - val_loss: 0.6819\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5986 - loss: 0.7968 - val_accuracy: 0.6099 - val_loss: 0.6724\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5689 - loss: 0.8403 - val_accuracy: 0.6188 - val_loss: 0.6758\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 0.7592 - val_accuracy: 0.6099 - val_loss: 0.6772\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6229 - loss: 0.7876 - val_accuracy: 0.6592 - val_loss: 0.6711\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5412 - loss: 0.8581 - val_accuracy: 0.6502 - val_loss: 0.6735\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6446 - loss: 0.6822 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5547 - loss: 19.5799 - val_accuracy: 0.6009 - val_loss: 8.3723\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5810 - loss: 14.2185 - val_accuracy: 0.5919 - val_loss: 7.5571\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5554 - loss: 15.9874 - val_accuracy: 0.6188 - val_loss: 6.4981\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5565 - loss: 14.6716 - val_accuracy: 0.6143 - val_loss: 5.4525\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5535 - loss: 13.4977 - val_accuracy: 0.5964 - val_loss: 5.7870\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5988 - loss: 11.6523 - val_accuracy: 0.6099 - val_loss: 7.0672\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5555 - loss: 12.7621 - val_accuracy: 0.6233 - val_loss: 5.5672\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5426 - loss: 13.4932 - val_accuracy: 0.6099 - val_loss: 4.9099\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5825 - loss: 14.0079 - val_accuracy: 0.6143 - val_loss: 4.7924\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6077 - loss: 11.9550 - val_accuracy: 0.6188 - val_loss: 7.2030\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5857 - loss: 11.9332 - val_accuracy: 0.6188 - val_loss: 6.2853\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6069 - loss: 11.5037 - val_accuracy: 0.6188 - val_loss: 5.9779\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6278 - loss: 9.8947 - val_accuracy: 0.6099 - val_loss: 4.1692\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6063 - loss: 10.8711 - val_accuracy: 0.6323 - val_loss: 4.7622\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5817 - loss: 11.8774 - val_accuracy: 0.6143 - val_loss: 5.7689\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5689 - loss: 11.6218 - val_accuracy: 0.6188 - val_loss: 5.1679\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6150 - loss: 10.4265 - val_accuracy: 0.6368 - val_loss: 3.8102\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5965 - loss: 11.0890 - val_accuracy: 0.6368 - val_loss: 4.7734\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5701 - loss: 11.7642 - val_accuracy: 0.6009 - val_loss: 8.5043\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 10.2435 - val_accuracy: 0.6323 - val_loss: 4.6715\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6504 - loss: 4.8944 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6050 - loss: 6.7432 - val_accuracy: 0.4484 - val_loss: 1.0622\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4617 - loss: 1.6231 - val_accuracy: 0.6099 - val_loss: 0.9316\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5680 - loss: 1.0403 - val_accuracy: 0.6099 - val_loss: 0.9238\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5609 - loss: 1.2975 - val_accuracy: 0.6009 - val_loss: 0.8984\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6082 - loss: 1.1442 - val_accuracy: 0.5202 - val_loss: 0.8124\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5506 - loss: 1.2474 - val_accuracy: 0.6323 - val_loss: 0.8365\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6067 - loss: 1.1020 - val_accuracy: 0.6099 - val_loss: 0.8701\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5645 - loss: 1.0869 - val_accuracy: 0.6278 - val_loss: 0.7539\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5977 - loss: 1.0236 - val_accuracy: 0.5919 - val_loss: 0.7207\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6290 - loss: 0.9434 - val_accuracy: 0.6009 - val_loss: 0.7988\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6197 - loss: 0.9848 - val_accuracy: 0.6278 - val_loss: 0.6909\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6127 - loss: 0.9279 - val_accuracy: 0.6143 - val_loss: 0.7839\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5986 - loss: 1.0438 - val_accuracy: 0.6233 - val_loss: 0.7156\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6296 - loss: 0.9011 - val_accuracy: 0.6368 - val_loss: 0.6665\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 0.9512 - val_accuracy: 0.6413 - val_loss: 0.6551\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 0.9736 - val_accuracy: 0.6457 - val_loss: 0.6566\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6222 - loss: 0.8822 - val_accuracy: 0.6368 - val_loss: 0.6638\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6214 - loss: 0.8999 - val_accuracy: 0.6233 - val_loss: 0.7201\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6081 - loss: 0.8987 - val_accuracy: 0.6726 - val_loss: 0.6564\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6038 - loss: 0.8989 - val_accuracy: 0.6637 - val_loss: 0.6522\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6605 - loss: 0.6277 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6011 - loss: 2.6904 - val_accuracy: 0.4126 - val_loss: 0.9296\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4600 - loss: 1.0300 - val_accuracy: 0.5964 - val_loss: 0.7419\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5884 - loss: 0.8007 - val_accuracy: 0.6054 - val_loss: 0.7424\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6038 - loss: 0.8713 - val_accuracy: 0.6054 - val_loss: 0.7163\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5734 - loss: 0.8794 - val_accuracy: 0.5964 - val_loss: 0.7080\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6033 - loss: 0.8230 - val_accuracy: 0.5919 - val_loss: 0.7091\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5424 - loss: 0.8997 - val_accuracy: 0.6233 - val_loss: 0.6906\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5571 - loss: 0.8687 - val_accuracy: 0.5695 - val_loss: 0.6918\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5416 - loss: 0.8354 - val_accuracy: 0.6143 - val_loss: 0.6848\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5554 - loss: 0.8446 - val_accuracy: 0.6143 - val_loss: 0.6853\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5851 - loss: 0.8219 - val_accuracy: 0.6143 - val_loss: 0.6894\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6026 - loss: 0.8038 - val_accuracy: 0.6099 - val_loss: 0.7006\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5876 - loss: 0.7761 - val_accuracy: 0.6099 - val_loss: 0.6770\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5544 - loss: 0.8364 - val_accuracy: 0.6188 - val_loss: 0.6755\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 0.7890 - val_accuracy: 0.6054 - val_loss: 0.6857\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6135 - loss: 0.7673 - val_accuracy: 0.6278 - val_loss: 0.6736\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6020 - loss: 0.8215 - val_accuracy: 0.6054 - val_loss: 0.6967\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5966 - loss: 0.7342 - val_accuracy: 0.6054 - val_loss: 0.6992\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6485 - loss: 0.7768 - val_accuracy: 0.6368 - val_loss: 0.6800\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5948 - loss: 0.7891 - val_accuracy: 0.5964 - val_loss: 0.6988\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6113 - loss: 0.6929 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.0005, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4636 - loss: 81.6511 - val_accuracy: 0.5919 - val_loss: 19.4615\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6165 - loss: 14.3979 - val_accuracy: 0.5785 - val_loss: 6.1841\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5689 - loss: 10.2298 - val_accuracy: 0.6143 - val_loss: 5.4003\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 10.2463 - val_accuracy: 0.6323 - val_loss: 5.1482\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6030 - loss: 9.5064 - val_accuracy: 0.5964 - val_loss: 4.7807\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5670 - loss: 9.9910 - val_accuracy: 0.6278 - val_loss: 4.9900\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5785 - loss: 9.1520 - val_accuracy: 0.6323 - val_loss: 5.1144\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6245 - loss: 8.2308 - val_accuracy: 0.6188 - val_loss: 5.4529\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5940 - loss: 10.1813 - val_accuracy: 0.6143 - val_loss: 5.7454\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 8.7891 - val_accuracy: 0.6054 - val_loss: 6.0572\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6052 - loss: 7.7230 - val_accuracy: 0.6054 - val_loss: 6.6959\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5973 - loss: 9.0307 - val_accuracy: 0.6009 - val_loss: 5.7175\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5867 - loss: 9.0205 - val_accuracy: 0.6233 - val_loss: 3.2855\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5420 - loss: 9.4751 - val_accuracy: 0.6323 - val_loss: 4.7241\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 8.4187 - val_accuracy: 0.6233 - val_loss: 4.9670\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5907 - loss: 7.1615 - val_accuracy: 0.6323 - val_loss: 2.7641\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5980 - loss: 8.7232 - val_accuracy: 0.6054 - val_loss: 5.0473\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5943 - loss: 7.4625 - val_accuracy: 0.6278 - val_loss: 4.3671\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5752 - loss: 7.1386 - val_accuracy: 0.6368 - val_loss: 3.3418\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5871 - loss: 7.5109 - val_accuracy: 0.6368 - val_loss: 3.6438\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6611 - loss: 3.6237 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5887 - loss: 3.4261 - val_accuracy: 0.4664 - val_loss: 0.9958\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5086 - loss: 1.2760 - val_accuracy: 0.5202 - val_loss: 0.8290\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4829 - loss: 1.0913 - val_accuracy: 0.5247 - val_loss: 0.7690\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5735 - loss: 0.9372 - val_accuracy: 0.5426 - val_loss: 0.7255\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5775 - loss: 0.9354 - val_accuracy: 0.6099 - val_loss: 0.7149\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5579 - loss: 0.8294 - val_accuracy: 0.6323 - val_loss: 0.7076\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5977 - loss: 0.8081 - val_accuracy: 0.6233 - val_loss: 0.7160\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6295 - loss: 0.7403 - val_accuracy: 0.6502 - val_loss: 0.6569\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6221 - loss: 0.7039 - val_accuracy: 0.6682 - val_loss: 0.6511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6399 - loss: 0.7294 - val_accuracy: 0.6906 - val_loss: 0.6392\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6619 - loss: 0.7378 - val_accuracy: 0.5381 - val_loss: 0.7251\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5945 - loss: 0.7547 - val_accuracy: 0.6502 - val_loss: 0.6453\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.6946 - val_accuracy: 0.6682 - val_loss: 0.6356\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6536 - loss: 0.7100 - val_accuracy: 0.6726 - val_loss: 0.6370\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6480 - loss: 0.6728 - val_accuracy: 0.6502 - val_loss: 0.6359\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6338 - loss: 0.7155 - val_accuracy: 0.6771 - val_loss: 0.6287\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6638 - loss: 0.6516 - val_accuracy: 0.6771 - val_loss: 0.6600\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6953 - loss: 0.6271 - val_accuracy: 0.6861 - val_loss: 0.6356\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7059 - loss: 0.6624 - val_accuracy: 0.6592 - val_loss: 0.6266\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6342 - loss: 0.7219 - val_accuracy: 0.6637 - val_loss: 0.6326\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6614 - loss: 0.6238 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4160 - loss: 3.5449 - val_accuracy: 0.5919 - val_loss: 0.7683\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6067 - loss: 0.9233 - val_accuracy: 0.6188 - val_loss: 0.6908\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5561 - loss: 0.8306 - val_accuracy: 0.6188 - val_loss: 0.6922\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5658 - loss: 0.8335 - val_accuracy: 0.6099 - val_loss: 0.6908\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5697 - loss: 0.8866 - val_accuracy: 0.6143 - val_loss: 0.6881\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5722 - loss: 0.8131 - val_accuracy: 0.5964 - val_loss: 0.7141\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5294 - loss: 0.8866 - val_accuracy: 0.6368 - val_loss: 0.6827\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6025 - loss: 0.7849 - val_accuracy: 0.6323 - val_loss: 0.6815\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5921 - loss: 0.7902 - val_accuracy: 0.6054 - val_loss: 0.6881\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5906 - loss: 0.8034 - val_accuracy: 0.6009 - val_loss: 0.6964\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5847 - loss: 0.8159 - val_accuracy: 0.6099 - val_loss: 0.6822\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6142 - loss: 0.8233 - val_accuracy: 0.6143 - val_loss: 0.6816\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 0.7357 - val_accuracy: 0.6457 - val_loss: 0.6776\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6220 - loss: 0.7586 - val_accuracy: 0.5561 - val_loss: 0.6972\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5801 - loss: 0.8063 - val_accuracy: 0.6457 - val_loss: 0.6769\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5674 - loss: 0.7995 - val_accuracy: 0.5919 - val_loss: 0.7411\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5761 - loss: 0.8400 - val_accuracy: 0.6009 - val_loss: 0.7278\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6179 - loss: 0.7928 - val_accuracy: 0.6368 - val_loss: 0.6762\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 0.7389 - val_accuracy: 0.6323 - val_loss: 0.6825\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6223 - loss: 0.7581 - val_accuracy: 0.6188 - val_loss: 0.6852\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5996 - loss: 0.6950 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3856 - loss: 171.4147 - val_accuracy: 0.6233 - val_loss: 7.5344\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5913 - loss: 16.7055 - val_accuracy: 0.6143 - val_loss: 9.9000\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5606 - loss: 11.4146 - val_accuracy: 0.6188 - val_loss: 7.9298\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5614 - loss: 8.9683 - val_accuracy: 0.6278 - val_loss: 5.2905\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5553 - loss: 8.9213 - val_accuracy: 0.5919 - val_loss: 4.2769\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5649 - loss: 7.3553 - val_accuracy: 0.6188 - val_loss: 4.2839\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5599 - loss: 7.6079 - val_accuracy: 0.6233 - val_loss: 3.5029\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5131 - loss: 7.6853 - val_accuracy: 0.6143 - val_loss: 4.4320\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5702 - loss: 7.2812 - val_accuracy: 0.6323 - val_loss: 2.9880\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5547 - loss: 5.7836 - val_accuracy: 0.6233 - val_loss: 2.5555\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5810 - loss: 5.7224 - val_accuracy: 0.5919 - val_loss: 3.4640\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5443 - loss: 5.7459 - val_accuracy: 0.5919 - val_loss: 3.9199\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5707 - loss: 5.7053 - val_accuracy: 0.5874 - val_loss: 3.1170\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5789 - loss: 5.3467 - val_accuracy: 0.6009 - val_loss: 2.5995\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6405 - loss: 5.0624 - val_accuracy: 0.5919 - val_loss: 3.8430\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5818 - loss: 5.8210 - val_accuracy: 0.6054 - val_loss: 3.3288\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6281 - loss: 5.3250 - val_accuracy: 0.5919 - val_loss: 3.9985\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 5.4442 - val_accuracy: 0.6188 - val_loss: 1.6298\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5266 - loss: 4.9991 - val_accuracy: 0.6054 - val_loss: 1.9688\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6053 - loss: 4.1857 - val_accuracy: 0.6143 - val_loss: 3.4493\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6156 - loss: 3.6546 \n",
      "Training model with: layers = 1, dropout = 0.2, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3891 - loss: 27.8834 - val_accuracy: 0.4081 - val_loss: 18.4514\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4200 - loss: 10.8558 - val_accuracy: 0.3901 - val_loss: 3.9578\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4962 - loss: 1.3221 - val_accuracy: 0.5785 - val_loss: 2.5649\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4534 - loss: 1.2842 - val_accuracy: 0.5785 - val_loss: 2.3238\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5061 - loss: 1.0956 - val_accuracy: 0.5785 - val_loss: 2.0792\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5378 - loss: 1.1946 - val_accuracy: 0.5919 - val_loss: 1.7987\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5281 - loss: 0.9856 - val_accuracy: 0.5695 - val_loss: 1.5719\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5428 - loss: 1.1474 - val_accuracy: 0.5381 - val_loss: 1.3048\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5182 - loss: 0.9909 - val_accuracy: 0.5336 - val_loss: 1.0500\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5251 - loss: 0.9418 - val_accuracy: 0.5650 - val_loss: 0.7028\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5979 - loss: 0.8010 - val_accuracy: 0.5650 - val_loss: 0.6945\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5720 - loss: 0.8580 - val_accuracy: 0.5919 - val_loss: 0.6876\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5793 - loss: 0.8364 - val_accuracy: 0.5919 - val_loss: 0.7032\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5697 - loss: 0.8908 - val_accuracy: 0.5695 - val_loss: 0.6925\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6009 - loss: 0.7850 - val_accuracy: 0.5740 - val_loss: 0.6987\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5688 - loss: 0.8381 - val_accuracy: 0.5650 - val_loss: 0.7209\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5824 - loss: 0.8021 - val_accuracy: 0.5695 - val_loss: 0.6981\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6208 - loss: 0.7708 - val_accuracy: 0.5874 - val_loss: 0.7009\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 0.8059 - val_accuracy: 0.5919 - val_loss: 0.7043\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5887 - loss: 0.7899 - val_accuracy: 0.5830 - val_loss: 0.7091\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5860 - loss: 0.7029 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5920 - loss: 3.9120 - val_accuracy: 0.5919 - val_loss: 1.5613\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 1.0921 - val_accuracy: 0.4843 - val_loss: 0.7805\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4911 - loss: 0.9436 - val_accuracy: 0.5650 - val_loss: 0.7715\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5263 - loss: 0.8759 - val_accuracy: 0.5874 - val_loss: 0.7780\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5354 - loss: 0.8472 - val_accuracy: 0.5785 - val_loss: 0.7536\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5354 - loss: 0.8093 - val_accuracy: 0.5830 - val_loss: 0.7729\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5563 - loss: 0.8071 - val_accuracy: 0.5830 - val_loss: 0.7633\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5467 - loss: 0.8693 - val_accuracy: 0.5830 - val_loss: 0.7553\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5465 - loss: 0.8164 - val_accuracy: 0.5830 - val_loss: 0.7608\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5652 - loss: 0.8479 - val_accuracy: 0.5830 - val_loss: 0.7345\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5885 - loss: 0.7975 - val_accuracy: 0.5830 - val_loss: 0.7188\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5591 - loss: 0.7856 - val_accuracy: 0.5874 - val_loss: 0.7278\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5529 - loss: 0.8091 - val_accuracy: 0.5740 - val_loss: 0.7060\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 0.7512 - val_accuracy: 0.6054 - val_loss: 0.6988\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5676 - loss: 0.7812 - val_accuracy: 0.5964 - val_loss: 0.6938\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6262 - loss: 0.7295 - val_accuracy: 0.6009 - val_loss: 0.6916\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5842 - loss: 0.7577 - val_accuracy: 0.6009 - val_loss: 0.6865\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5686 - loss: 0.7322 - val_accuracy: 0.6054 - val_loss: 0.6877\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 0.7216 - val_accuracy: 0.6099 - val_loss: 0.6826\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 0.7131 - val_accuracy: 0.6278 - val_loss: 0.6755\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6010 - loss: 0.6745 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5964 - loss: 94.2479 - val_accuracy: 0.5919 - val_loss: 34.9937\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 19.8071 - val_accuracy: 0.5785 - val_loss: 15.8237\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5621 - loss: 14.4442 - val_accuracy: 0.5874 - val_loss: 9.2127\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5538 - loss: 12.7681 - val_accuracy: 0.5919 - val_loss: 7.0932\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5589 - loss: 11.1318 - val_accuracy: 0.5785 - val_loss: 9.4470\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5930 - loss: 11.5829 - val_accuracy: 0.5874 - val_loss: 11.3929\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5920 - loss: 11.0942 - val_accuracy: 0.5785 - val_loss: 6.2225\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5678 - loss: 10.0525 - val_accuracy: 0.5830 - val_loss: 6.0904\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5823 - loss: 11.7248 - val_accuracy: 0.5785 - val_loss: 8.5529\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5489 - loss: 12.6972 - val_accuracy: 0.5830 - val_loss: 5.6953\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5777 - loss: 11.4901 - val_accuracy: 0.5830 - val_loss: 9.0729\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6156 - loss: 9.4415 - val_accuracy: 0.5740 - val_loss: 5.6489\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5515 - loss: 9.8716 - val_accuracy: 0.5874 - val_loss: 4.0281\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5414 - loss: 10.5959 - val_accuracy: 0.5874 - val_loss: 6.1953\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5798 - loss: 9.5164 - val_accuracy: 0.5874 - val_loss: 5.5629\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5669 - loss: 9.5114 - val_accuracy: 0.5919 - val_loss: 3.9127\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 8.8144 - val_accuracy: 0.6009 - val_loss: 4.3087\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5636 - loss: 8.8329 - val_accuracy: 0.5830 - val_loss: 6.8601\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5073 - loss: 13.0295 - val_accuracy: 0.5919 - val_loss: 4.8207\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5364 - loss: 8.1125 - val_accuracy: 0.6009 - val_loss: 3.2020\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5547 - loss: 3.3240 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5736 - loss: 10.0808 - val_accuracy: 0.5919 - val_loss: 0.9035\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5234 - loss: 1.6704 - val_accuracy: 0.6413 - val_loss: 0.9469\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - loss: 1.1977 - val_accuracy: 0.6233 - val_loss: 0.8546\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5631 - loss: 1.4074 - val_accuracy: 0.5874 - val_loss: 0.7966\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5268 - loss: 1.3179 - val_accuracy: 0.5874 - val_loss: 0.9637\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6092 - loss: 1.3816 - val_accuracy: 0.5919 - val_loss: 0.9064\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5326 - loss: 1.6453 - val_accuracy: 0.6323 - val_loss: 0.7435\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 1.1771 - val_accuracy: 0.6009 - val_loss: 0.8637\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5688 - loss: 1.3627 - val_accuracy: 0.4664 - val_loss: 0.7901\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5449 - loss: 1.3040 - val_accuracy: 0.6143 - val_loss: 0.7181\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5873 - loss: 1.2489 - val_accuracy: 0.6009 - val_loss: 0.7699\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6314 - loss: 1.0746 - val_accuracy: 0.5785 - val_loss: 0.7009\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5628 - loss: 1.0449 - val_accuracy: 0.6099 - val_loss: 0.7104\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6023 - loss: 1.1165 - val_accuracy: 0.6009 - val_loss: 0.7562\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6105 - loss: 1.1993 - val_accuracy: 0.6143 - val_loss: 0.7503\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 1.1754 - val_accuracy: 0.5247 - val_loss: 0.7386\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6283 - loss: 1.0378 - val_accuracy: 0.6099 - val_loss: 0.8036\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5777 - loss: 1.2519 - val_accuracy: 0.5964 - val_loss: 0.7078\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 1.2117 - val_accuracy: 0.5830 - val_loss: 0.7021\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5888 - loss: 1.0270 - val_accuracy: 0.6054 - val_loss: 0.6940\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 0.6928 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4196 - loss: 4.5557 - val_accuracy: 0.4036 - val_loss: 1.2034\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4855 - loss: 1.0715 - val_accuracy: 0.6099 - val_loss: 0.7876\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5907 - loss: 0.9055 - val_accuracy: 0.6233 - val_loss: 0.6935\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6092 - loss: 0.8199 - val_accuracy: 0.6323 - val_loss: 0.6987\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6100 - loss: 0.9118 - val_accuracy: 0.6368 - val_loss: 0.6937\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6151 - loss: 0.8242 - val_accuracy: 0.6278 - val_loss: 0.6921\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5947 - loss: 0.8382 - val_accuracy: 0.6368 - val_loss: 0.6887\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5670 - loss: 0.9093 - val_accuracy: 0.6413 - val_loss: 0.6854\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5686 - loss: 0.8589 - val_accuracy: 0.6323 - val_loss: 0.6842\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5704 - loss: 0.8223 - val_accuracy: 0.6278 - val_loss: 0.6949\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6361 - loss: 0.7810 - val_accuracy: 0.6188 - val_loss: 0.6963\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6229 - loss: 0.8038 - val_accuracy: 0.6323 - val_loss: 0.6791\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5995 - loss: 0.8765 - val_accuracy: 0.6457 - val_loss: 0.6757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5971 - loss: 0.7932 - val_accuracy: 0.6457 - val_loss: 0.6772\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5978 - loss: 0.7850 - val_accuracy: 0.6009 - val_loss: 0.6924\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6231 - loss: 0.7451 - val_accuracy: 0.6323 - val_loss: 0.6832\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5948 - loss: 0.8470 - val_accuracy: 0.6368 - val_loss: 0.6778\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5865 - loss: 0.7861 - val_accuracy: 0.6368 - val_loss: 0.6817\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6194 - loss: 0.8180 - val_accuracy: 0.6413 - val_loss: 0.6755\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6079 - loss: 0.7789 - val_accuracy: 0.6278 - val_loss: 0.6772\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 0.6579 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.0005, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5838 - loss: 212.8639 - val_accuracy: 0.5919 - val_loss: 170.6566\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6125 - loss: 130.8652 - val_accuracy: 0.5919 - val_loss: 93.8344\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 73.0477 - val_accuracy: 0.5874 - val_loss: 20.1573\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5307 - loss: 13.6268 - val_accuracy: 0.5830 - val_loss: 10.0466\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 10.3515 - val_accuracy: 0.6009 - val_loss: 6.2491\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5517 - loss: 9.9414 - val_accuracy: 0.5650 - val_loss: 3.9310\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5744 - loss: 9.1826 - val_accuracy: 0.5740 - val_loss: 2.3823\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5649 - loss: 9.1647 - val_accuracy: 0.5919 - val_loss: 4.9506\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5720 - loss: 9.0932 - val_accuracy: 0.6009 - val_loss: 4.4183\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5750 - loss: 8.6949 - val_accuracy: 0.5874 - val_loss: 5.3086\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5815 - loss: 7.9056 - val_accuracy: 0.5874 - val_loss: 4.9376\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5823 - loss: 8.5646 - val_accuracy: 0.5874 - val_loss: 6.1030\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5982 - loss: 8.3584 - val_accuracy: 0.6054 - val_loss: 2.5820\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6156 - loss: 6.5548 - val_accuracy: 0.6054 - val_loss: 2.6759\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6090 - loss: 7.3433 - val_accuracy: 0.6099 - val_loss: 2.5034\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6068 - loss: 6.2143 - val_accuracy: 0.6009 - val_loss: 2.7468\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6169 - loss: 6.2913 - val_accuracy: 0.5919 - val_loss: 5.4552\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 6.5225 - val_accuracy: 0.6099 - val_loss: 3.3609\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6173 - loss: 6.4822 - val_accuracy: 0.6099 - val_loss: 3.3513\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5874 - loss: 6.9848 - val_accuracy: 0.6143 - val_loss: 2.6656\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6088 - loss: 2.5729 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4041 - loss: 12.2445 - val_accuracy: 0.5964 - val_loss: 0.9586\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6233 - loss: 1.6091 - val_accuracy: 0.5291 - val_loss: 0.9421\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 1.1940 - val_accuracy: 0.5919 - val_loss: 0.9001\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 1.2025 - val_accuracy: 0.6009 - val_loss: 0.8674\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6285 - loss: 1.1255 - val_accuracy: 0.6054 - val_loss: 0.8578\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5892 - loss: 1.2471 - val_accuracy: 0.5874 - val_loss: 0.8386\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6126 - loss: 1.1316 - val_accuracy: 0.6099 - val_loss: 0.7944\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5925 - loss: 1.1322 - val_accuracy: 0.5964 - val_loss: 0.7653\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6217 - loss: 1.1516 - val_accuracy: 0.6009 - val_loss: 0.9020\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6188 - loss: 0.9791 - val_accuracy: 0.6054 - val_loss: 0.8054\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5983 - loss: 1.0404 - val_accuracy: 0.6099 - val_loss: 0.7372\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5934 - loss: 1.0811 - val_accuracy: 0.6188 - val_loss: 0.8344\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5886 - loss: 1.0892 - val_accuracy: 0.6233 - val_loss: 0.7430\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5987 - loss: 1.0660 - val_accuracy: 0.5785 - val_loss: 0.8254\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6267 - loss: 1.0235 - val_accuracy: 0.6233 - val_loss: 0.7484\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6032 - loss: 1.1479 - val_accuracy: 0.6188 - val_loss: 0.7443\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5834 - loss: 1.0504 - val_accuracy: 0.5919 - val_loss: 0.7344\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6142 - loss: 1.0301 - val_accuracy: 0.6143 - val_loss: 0.7008\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6343 - loss: 1.0503 - val_accuracy: 0.5919 - val_loss: 0.7746\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5876 - loss: 1.1995 - val_accuracy: 0.6143 - val_loss: 0.6930\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5921 - loss: 0.6774 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5849 - loss: 1.7234 - val_accuracy: 0.5561 - val_loss: 0.7645\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5788 - loss: 0.8868 - val_accuracy: 0.5964 - val_loss: 0.7591\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5756 - loss: 0.8823 - val_accuracy: 0.5291 - val_loss: 0.7498\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5696 - loss: 0.8570 - val_accuracy: 0.6143 - val_loss: 0.7408\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5560 - loss: 0.9228 - val_accuracy: 0.6099 - val_loss: 0.7544\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5706 - loss: 0.8733 - val_accuracy: 0.6188 - val_loss: 0.7224\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5670 - loss: 0.8997 - val_accuracy: 0.5561 - val_loss: 0.7152\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5673 - loss: 0.8897 - val_accuracy: 0.5785 - val_loss: 0.7074\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 0.8028 - val_accuracy: 0.6323 - val_loss: 0.7013\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5748 - loss: 0.8586 - val_accuracy: 0.5067 - val_loss: 0.7040\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5646 - loss: 0.8545 - val_accuracy: 0.6009 - val_loss: 0.6944\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5691 - loss: 0.7921 - val_accuracy: 0.6143 - val_loss: 0.7078\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6270 - loss: 0.8296 - val_accuracy: 0.6009 - val_loss: 0.7174\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6057 - loss: 0.8024 - val_accuracy: 0.6009 - val_loss: 0.6893\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5942 - loss: 0.8666 - val_accuracy: 0.6278 - val_loss: 0.6850\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5806 - loss: 0.8111 - val_accuracy: 0.6278 - val_loss: 0.6845\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5957 - loss: 0.7840 - val_accuracy: 0.6099 - val_loss: 0.6881\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5976 - loss: 0.7897 - val_accuracy: 0.6368 - val_loss: 0.6781\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6096 - loss: 0.7617 - val_accuracy: 0.6009 - val_loss: 0.6875\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6468 - loss: 0.7199 - val_accuracy: 0.5516 - val_loss: 0.6904\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5265 - loss: 0.6849 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5882 - loss: 10.6207 - val_accuracy: 0.5964 - val_loss: 3.5253\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5784 - loss: 10.8282 - val_accuracy: 0.5919 - val_loss: 5.0296\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5989 - loss: 8.6988 - val_accuracy: 0.5919 - val_loss: 6.6964\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5563 - loss: 10.5760 - val_accuracy: 0.5471 - val_loss: 1.6389\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 8.4727 - val_accuracy: 0.6009 - val_loss: 3.2413\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5899 - loss: 7.5324 - val_accuracy: 0.5919 - val_loss: 5.1533\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5688 - loss: 9.2391 - val_accuracy: 0.6009 - val_loss: 4.8861\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5825 - loss: 7.6630 - val_accuracy: 0.6233 - val_loss: 4.0408\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6078 - loss: 7.5302 - val_accuracy: 0.6233 - val_loss: 2.6380\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6050 - loss: 7.9617 - val_accuracy: 0.6009 - val_loss: 5.6227\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5783 - loss: 7.1207 - val_accuracy: 0.5964 - val_loss: 3.3211\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5869 - loss: 6.9302 - val_accuracy: 0.6054 - val_loss: 4.7047\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5698 - loss: 8.9794 - val_accuracy: 0.6099 - val_loss: 4.7490\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5796 - loss: 7.1193 - val_accuracy: 0.6054 - val_loss: 5.2120\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 7.1972 - val_accuracy: 0.6054 - val_loss: 4.8353\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6089 - loss: 6.3690 - val_accuracy: 0.6413 - val_loss: 2.2181\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5864 - loss: 6.1724 - val_accuracy: 0.6413 - val_loss: 2.7495\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5914 - loss: 6.7650 - val_accuracy: 0.6457 - val_loss: 2.7143\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6332 - loss: 6.0312 - val_accuracy: 0.6009 - val_loss: 4.2005\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5975 - loss: 5.6467 - val_accuracy: 0.6054 - val_loss: 5.0953\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5973 - loss: 6.1941 \n",
      "Training model with: layers = 1, dropout = 0.3, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4238 - loss: 9.9441 - val_accuracy: 0.4036 - val_loss: 1.0612\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5151 - loss: 1.3431 - val_accuracy: 0.5695 - val_loss: 0.6980\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4950 - loss: 1.0331 - val_accuracy: 0.5964 - val_loss: 0.7535\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 0.9355 - val_accuracy: 0.6233 - val_loss: 0.7014\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5626 - loss: 0.9179 - val_accuracy: 0.6188 - val_loss: 0.7236\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5691 - loss: 0.9670 - val_accuracy: 0.5919 - val_loss: 0.7146\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5708 - loss: 1.0477 - val_accuracy: 0.6188 - val_loss: 0.6618\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5360 - loss: 1.0043 - val_accuracy: 0.6233 - val_loss: 0.6566\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6563 - loss: 0.8594 - val_accuracy: 0.6457 - val_loss: 0.6476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5673 - loss: 0.9482 - val_accuracy: 0.6413 - val_loss: 0.6667\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6057 - loss: 0.8563 - val_accuracy: 0.6413 - val_loss: 0.6473\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6125 - loss: 0.8447 - val_accuracy: 0.6592 - val_loss: 0.6430\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5885 - loss: 0.9586 - val_accuracy: 0.6188 - val_loss: 0.6442\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6005 - loss: 0.8845 - val_accuracy: 0.6592 - val_loss: 0.6424\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6020 - loss: 0.8681 - val_accuracy: 0.6637 - val_loss: 0.6408\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.8224 - val_accuracy: 0.6637 - val_loss: 0.6373\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6396 - loss: 0.7585 - val_accuracy: 0.6726 - val_loss: 0.6199\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6181 - loss: 0.8928 - val_accuracy: 0.6188 - val_loss: 0.6468\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6404 - loss: 0.7827 - val_accuracy: 0.6637 - val_loss: 0.6227\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6290 - loss: 0.8053 - val_accuracy: 0.6233 - val_loss: 0.6276\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6360 - loss: 0.6227 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5191 - loss: 3.2864 - val_accuracy: 0.4081 - val_loss: 1.0037\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4972 - loss: 1.5859 - val_accuracy: 0.5785 - val_loss: 0.9179\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5649 - loss: 1.3332 - val_accuracy: 0.6099 - val_loss: 0.7400\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5802 - loss: 1.0992 - val_accuracy: 0.5919 - val_loss: 0.7390\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5959 - loss: 1.0645 - val_accuracy: 0.5919 - val_loss: 0.7939\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6065 - loss: 1.0469 - val_accuracy: 0.6188 - val_loss: 0.7074\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5190 - loss: 1.1737 - val_accuracy: 0.5919 - val_loss: 1.2103\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5321 - loss: 1.1219 - val_accuracy: 0.6009 - val_loss: 0.8181\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5982 - loss: 1.0647 - val_accuracy: 0.6099 - val_loss: 0.7286\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5636 - loss: 1.0577 - val_accuracy: 0.5874 - val_loss: 0.8512\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5573 - loss: 1.0900 - val_accuracy: 0.5919 - val_loss: 1.0627\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6077 - loss: 0.9572 - val_accuracy: 0.5964 - val_loss: 0.8537\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 0.8960 - val_accuracy: 0.6278 - val_loss: 0.7038\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5777 - loss: 0.9092 - val_accuracy: 0.6368 - val_loss: 0.7345\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5499 - loss: 1.0403 - val_accuracy: 0.5919 - val_loss: 0.9182\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6315 - loss: 0.8523 - val_accuracy: 0.6009 - val_loss: 0.7925\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6055 - loss: 0.8723 - val_accuracy: 0.6233 - val_loss: 0.7345\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6192 - loss: 0.8130 - val_accuracy: 0.6009 - val_loss: 0.8613\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6053 - loss: 0.8104 - val_accuracy: 0.6009 - val_loss: 0.8173\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5719 - loss: 0.8898 - val_accuracy: 0.6099 - val_loss: 0.7301\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6149 - loss: 0.7270 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5649 - loss: 38.8267 - val_accuracy: 0.5785 - val_loss: 15.7245\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5218 - loss: 30.9007 - val_accuracy: 0.6054 - val_loss: 10.4566\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5652 - loss: 36.4627 - val_accuracy: 0.6143 - val_loss: 7.4691\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5830 - loss: 29.5250 - val_accuracy: 0.5919 - val_loss: 25.3200\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6334 - loss: 20.9118 - val_accuracy: 0.6188 - val_loss: 8.5661\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5912 - loss: 24.7910 - val_accuracy: 0.6188 - val_loss: 12.0734\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5840 - loss: 19.7140 - val_accuracy: 0.5067 - val_loss: 12.8879\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5655 - loss: 24.4203 - val_accuracy: 0.6143 - val_loss: 14.0768\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6131 - loss: 20.3316 - val_accuracy: 0.5964 - val_loss: 18.9280\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6281 - loss: 22.3893 - val_accuracy: 0.6188 - val_loss: 10.5462\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5914 - loss: 17.6616 - val_accuracy: 0.6233 - val_loss: 9.0700\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5568 - loss: 15.9248 - val_accuracy: 0.6099 - val_loss: 13.0597\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6104 - loss: 17.3144 - val_accuracy: 0.6143 - val_loss: 9.4510\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6192 - loss: 15.3406 - val_accuracy: 0.5785 - val_loss: 9.4530\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5930 - loss: 14.8928 - val_accuracy: 0.6009 - val_loss: 5.7552\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5937 - loss: 11.9672 - val_accuracy: 0.6457 - val_loss: 5.9253\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6266 - loss: 10.6860 - val_accuracy: 0.6009 - val_loss: 14.2152\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5863 - loss: 12.6883 - val_accuracy: 0.6368 - val_loss: 5.6673\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5977 - loss: 12.4384 - val_accuracy: 0.6502 - val_loss: 3.5372\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5930 - loss: 10.8950 - val_accuracy: 0.6413 - val_loss: 6.8261\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6537 - loss: 6.9230 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5286 - loss: 10.2959 - val_accuracy: 0.5964 - val_loss: 3.7071\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5506 - loss: 3.3768 - val_accuracy: 0.6099 - val_loss: 1.5458\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5608 - loss: 2.4239 - val_accuracy: 0.6233 - val_loss: 1.7064\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5702 - loss: 2.2332 - val_accuracy: 0.6099 - val_loss: 1.1676\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 1.8416 - val_accuracy: 0.5830 - val_loss: 1.8161\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5595 - loss: 1.7579 - val_accuracy: 0.5785 - val_loss: 2.1128\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5615 - loss: 1.8002 - val_accuracy: 0.5067 - val_loss: 1.2413\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5928 - loss: 1.5288 - val_accuracy: 0.6278 - val_loss: 0.9200\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5713 - loss: 1.5535 - val_accuracy: 0.6278 - val_loss: 0.9442\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6288 - loss: 1.3076 - val_accuracy: 0.4260 - val_loss: 1.3687\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6005 - loss: 1.2697 - val_accuracy: 0.4126 - val_loss: 1.8516\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5848 - loss: 1.2126 - val_accuracy: 0.4215 - val_loss: 1.5840\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 1.1024 - val_accuracy: 0.5067 - val_loss: 1.1620\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5716 - loss: 1.3436 - val_accuracy: 0.6143 - val_loss: 0.8879\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5912 - loss: 1.2196 - val_accuracy: 0.4529 - val_loss: 1.4301\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6362 - loss: 0.9651 - val_accuracy: 0.4439 - val_loss: 1.4267\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6111 - loss: 1.0496 - val_accuracy: 0.4843 - val_loss: 1.1964\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 1.1394 - val_accuracy: 0.4798 - val_loss: 1.1800\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6023 - loss: 1.0341 - val_accuracy: 0.5964 - val_loss: 0.9349\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5888 - loss: 0.9885 - val_accuracy: 0.5964 - val_loss: 0.7655\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6171 - loss: 0.6680 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4991 - loss: 3.0014 - val_accuracy: 0.6054 - val_loss: 0.7763\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5227 - loss: 1.5801 - val_accuracy: 0.6233 - val_loss: 0.7092\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5269 - loss: 1.4445 - val_accuracy: 0.5202 - val_loss: 0.7414\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5611 - loss: 1.3111 - val_accuracy: 0.6143 - val_loss: 0.7968\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5795 - loss: 1.4269 - val_accuracy: 0.6233 - val_loss: 0.6912\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5347 - loss: 1.3560 - val_accuracy: 0.6009 - val_loss: 0.8956\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5525 - loss: 1.5159 - val_accuracy: 0.5919 - val_loss: 0.9803\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5567 - loss: 1.2356 - val_accuracy: 0.6143 - val_loss: 0.6910\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5205 - loss: 1.2350 - val_accuracy: 0.5964 - val_loss: 0.7053\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5527 - loss: 1.1705 - val_accuracy: 0.6413 - val_loss: 0.7013\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5505 - loss: 1.1766 - val_accuracy: 0.6233 - val_loss: 0.6795\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5880 - loss: 0.9521 - val_accuracy: 0.6457 - val_loss: 0.6805\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5548 - loss: 1.0019 - val_accuracy: 0.6413 - val_loss: 0.6746\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5769 - loss: 1.0305 - val_accuracy: 0.6233 - val_loss: 0.7084\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6037 - loss: 0.8408 - val_accuracy: 0.5919 - val_loss: 0.9905\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6298 - loss: 0.9278 - val_accuracy: 0.6009 - val_loss: 0.9335\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 0.9695 - val_accuracy: 0.6368 - val_loss: 0.6899\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6109 - loss: 0.8528 - val_accuracy: 0.4350 - val_loss: 0.8378\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5390 - loss: 0.9790 - val_accuracy: 0.4126 - val_loss: 0.9405\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5586 - loss: 0.9399 - val_accuracy: 0.6502 - val_loss: 0.7179\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6219 - loss: 0.7465 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.0005, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5173 - loss: 50.3600 - val_accuracy: 0.6009 - val_loss: 24.5729\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5335 - loss: 27.4806 - val_accuracy: 0.6188 - val_loss: 8.9120\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5508 - loss: 18.3205 - val_accuracy: 0.5830 - val_loss: 4.2913\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5513 - loss: 13.7153 - val_accuracy: 0.5874 - val_loss: 12.3320\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6222 - loss: 11.9394 - val_accuracy: 0.5964 - val_loss: 12.7222\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5879 - loss: 12.2167 - val_accuracy: 0.6188 - val_loss: 5.5916\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5750 - loss: 14.1612 - val_accuracy: 0.6368 - val_loss: 4.2840\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 11.6292 - val_accuracy: 0.5919 - val_loss: 13.3517\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5905 - loss: 13.7448 - val_accuracy: 0.6233 - val_loss: 8.3248\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5878 - loss: 10.9051 - val_accuracy: 0.5964 - val_loss: 10.3047\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6273 - loss: 8.9801 - val_accuracy: 0.6054 - val_loss: 7.9251\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5969 - loss: 9.6000 - val_accuracy: 0.5740 - val_loss: 9.8481\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5793 - loss: 10.6836 - val_accuracy: 0.6054 - val_loss: 6.9930\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6040 - loss: 14.2859 - val_accuracy: 0.6099 - val_loss: 9.5727\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6023 - loss: 11.1531 - val_accuracy: 0.6323 - val_loss: 7.7140\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5992 - loss: 9.0095 - val_accuracy: 0.6233 - val_loss: 5.8640\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5800 - loss: 8.7056 - val_accuracy: 0.5919 - val_loss: 12.1157\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 9.8357 - val_accuracy: 0.6143 - val_loss: 8.8116\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5774 - loss: 8.6930 - val_accuracy: 0.6099 - val_loss: 6.1488\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6285 - loss: 7.2155 - val_accuracy: 0.6278 - val_loss: 3.5452\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6518 - loss: 2.7675 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4844 - loss: 4.1084 - val_accuracy: 0.6009 - val_loss: 1.7798\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4673 - loss: 2.1710 - val_accuracy: 0.6009 - val_loss: 1.6965\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5460 - loss: 1.5900 - val_accuracy: 0.4574 - val_loss: 0.9069\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5609 - loss: 1.4705 - val_accuracy: 0.4126 - val_loss: 1.3124\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5366 - loss: 1.4749 - val_accuracy: 0.4126 - val_loss: 1.4557\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5644 - loss: 1.3217 - val_accuracy: 0.4126 - val_loss: 2.8876\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5753 - loss: 1.4834 - val_accuracy: 0.4126 - val_loss: 1.6672\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6253 - loss: 1.1361 - val_accuracy: 0.4126 - val_loss: 2.8178\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5766 - loss: 1.3253 - val_accuracy: 0.4126 - val_loss: 1.4234\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6170 - loss: 1.0690 - val_accuracy: 0.5067 - val_loss: 0.8984\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5852 - loss: 1.2489 - val_accuracy: 0.4126 - val_loss: 2.4568\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6162 - loss: 1.0449 - val_accuracy: 0.4126 - val_loss: 2.5672\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6175 - loss: 1.0149 - val_accuracy: 0.4126 - val_loss: 2.5697\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6237 - loss: 0.9191 - val_accuracy: 0.4126 - val_loss: 2.3907\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6182 - loss: 0.9482 - val_accuracy: 0.4126 - val_loss: 1.4058\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6070 - loss: 0.9405 - val_accuracy: 0.4126 - val_loss: 1.9615\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5858 - loss: 1.0216 - val_accuracy: 0.4619 - val_loss: 1.0272\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6067 - loss: 1.0354 - val_accuracy: 0.4126 - val_loss: 1.5947\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6384 - loss: 0.8662 - val_accuracy: 0.4170 - val_loss: 2.6095\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6029 - loss: 1.0360 - val_accuracy: 0.4126 - val_loss: 1.5166\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3986 - loss: 1.6463 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4565 - loss: 11.5269 - val_accuracy: 0.5919 - val_loss: 1.6313\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4831 - loss: 1.6036 - val_accuracy: 0.6143 - val_loss: 0.8039\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4833 - loss: 1.2823 - val_accuracy: 0.5157 - val_loss: 0.8150\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5010 - loss: 1.2649 - val_accuracy: 0.6368 - val_loss: 0.7504\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5128 - loss: 1.1420 - val_accuracy: 0.3812 - val_loss: 0.8039\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4984 - loss: 1.1191 - val_accuracy: 0.6009 - val_loss: 0.6916\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4962 - loss: 1.1231 - val_accuracy: 0.5471 - val_loss: 0.7198\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5532 - loss: 1.0095 - val_accuracy: 0.3857 - val_loss: 0.8485\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5292 - loss: 1.0085 - val_accuracy: 0.3901 - val_loss: 0.8617\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5425 - loss: 0.9824 - val_accuracy: 0.5964 - val_loss: 0.7161\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5972 - loss: 0.8961 - val_accuracy: 0.4170 - val_loss: 0.8686\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5485 - loss: 0.8584 - val_accuracy: 0.6457 - val_loss: 0.7359\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5989 - loss: 0.7642 - val_accuracy: 0.5381 - val_loss: 0.7687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5821 - loss: 0.7693 - val_accuracy: 0.6547 - val_loss: 0.7400\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5998 - loss: 0.7731 - val_accuracy: 0.5874 - val_loss: 0.7383\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5613 - loss: 0.8370 - val_accuracy: 0.6188 - val_loss: 0.7173\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5510 - loss: 0.8528 - val_accuracy: 0.6054 - val_loss: 0.8902\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6134 - loss: 0.7425 - val_accuracy: 0.6054 - val_loss: 0.8436\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6296 - loss: 0.7276 - val_accuracy: 0.6278 - val_loss: 0.7584\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 0.7538 - val_accuracy: 0.6233 - val_loss: 0.7450\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6139 - loss: 0.7687 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4213 - loss: 686.8705 - val_accuracy: 0.5919 - val_loss: 146.7792\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6108 - loss: 90.2765 - val_accuracy: 0.5964 - val_loss: 21.0881\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5923 - loss: 37.5389 - val_accuracy: 0.4529 - val_loss: 21.4083\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5464 - loss: 35.6731 - val_accuracy: 0.5919 - val_loss: 17.4205\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 32.0542 - val_accuracy: 0.4888 - val_loss: 10.7166\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5714 - loss: 28.2045 - val_accuracy: 0.5919 - val_loss: 20.1032\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5990 - loss: 24.3754 - val_accuracy: 0.6009 - val_loss: 9.0503\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6093 - loss: 20.1503 - val_accuracy: 0.5919 - val_loss: 24.1815\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5708 - loss: 21.4909 - val_accuracy: 0.6009 - val_loss: 21.1837\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5788 - loss: 20.9460 - val_accuracy: 0.6054 - val_loss: 20.7223\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5715 - loss: 21.7977 - val_accuracy: 0.6323 - val_loss: 16.5270\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5830 - loss: 21.2784 - val_accuracy: 0.6413 - val_loss: 12.1084\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6154 - loss: 17.7662 - val_accuracy: 0.6323 - val_loss: 10.9418\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6244 - loss: 17.9429 - val_accuracy: 0.6368 - val_loss: 12.5830\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6138 - loss: 15.9158 - val_accuracy: 0.6323 - val_loss: 15.9877\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5909 - loss: 19.2997 - val_accuracy: 0.6413 - val_loss: 12.4379\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6278 - loss: 16.4585 - val_accuracy: 0.6143 - val_loss: 15.4426\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6136 - loss: 14.9281 - val_accuracy: 0.6413 - val_loss: 12.8601\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6287 - loss: 12.8617 - val_accuracy: 0.6099 - val_loss: 17.5443\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6100 - loss: 14.7480 - val_accuracy: 0.6323 - val_loss: 12.3971\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6344 - loss: 13.6917 \n",
      "Training model with: layers = 2, dropout = 0.1, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4376 - loss: 11.1823 - val_accuracy: 0.5067 - val_loss: 1.0749\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4531 - loss: 2.9063 - val_accuracy: 0.5561 - val_loss: 0.9868\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5158 - loss: 2.1316 - val_accuracy: 0.5022 - val_loss: 0.8365\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5477 - loss: 1.4708 - val_accuracy: 0.4170 - val_loss: 1.5257\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5443 - loss: 1.5394 - val_accuracy: 0.4395 - val_loss: 1.2069\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5900 - loss: 1.2887 - val_accuracy: 0.4170 - val_loss: 1.5850\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5657 - loss: 1.3780 - val_accuracy: 0.3991 - val_loss: 2.0423\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5324 - loss: 1.2519 - val_accuracy: 0.4036 - val_loss: 2.0724\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6144 - loss: 1.9879 - val_accuracy: 0.4215 - val_loss: 1.4746\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 1.0978 - val_accuracy: 0.4350 - val_loss: 1.1600\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5819 - loss: 1.1558 - val_accuracy: 0.4170 - val_loss: 2.8909\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 1.0993 - val_accuracy: 0.4170 - val_loss: 1.9852\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5680 - loss: 1.1315 - val_accuracy: 0.4170 - val_loss: 1.7968\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6293 - loss: 0.9035 - val_accuracy: 0.4170 - val_loss: 1.8120\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: 1.1333 - val_accuracy: 0.4170 - val_loss: 2.0089\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6062 - loss: 0.9432 - val_accuracy: 0.4170 - val_loss: 1.5843\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6343 - loss: 0.9227 - val_accuracy: 0.4215 - val_loss: 1.4060\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.9525 - val_accuracy: 0.4170 - val_loss: 1.6060\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6314 - loss: 0.8332 - val_accuracy: 0.4081 - val_loss: 2.1523\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6590 - loss: 0.8344 - val_accuracy: 0.4126 - val_loss: 2.0028\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3986 - loss: 2.3451 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4681 - loss: 2.7383 - val_accuracy: 0.6143 - val_loss: 0.6815\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5573 - loss: 0.9167 - val_accuracy: 0.5785 - val_loss: 0.7842\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5530 - loss: 0.9612 - val_accuracy: 0.5830 - val_loss: 0.8519\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5935 - loss: 0.8288 - val_accuracy: 0.5874 - val_loss: 0.6624\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5568 - loss: 0.8265 - val_accuracy: 0.5919 - val_loss: 0.6915\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5966 - loss: 0.7944 - val_accuracy: 0.5964 - val_loss: 0.7105\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5897 - loss: 0.7679 - val_accuracy: 0.5919 - val_loss: 0.8360\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6217 - loss: 0.7532 - val_accuracy: 0.5874 - val_loss: 0.6870\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 0.6950 - val_accuracy: 0.5964 - val_loss: 0.7482\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6139 - loss: 0.7552 - val_accuracy: 0.5919 - val_loss: 0.8007\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6275 - loss: 0.7321 - val_accuracy: 0.5874 - val_loss: 0.7402\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 0.6923 - val_accuracy: 0.5919 - val_loss: 0.8543\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6122 - loss: 0.7384 - val_accuracy: 0.5919 - val_loss: 0.7695\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5958 - loss: 0.6965 - val_accuracy: 0.5964 - val_loss: 0.7759\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6399 - loss: 0.6773 - val_accuracy: 0.5964 - val_loss: 0.7567\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6385 - loss: 0.6978 - val_accuracy: 0.6009 - val_loss: 0.7352\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6373 - loss: 0.6651 - val_accuracy: 0.6054 - val_loss: 0.7026\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6501 - loss: 0.6416 - val_accuracy: 0.6099 - val_loss: 0.6716\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6417 - loss: 0.6644 - val_accuracy: 0.5919 - val_loss: 0.8273\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6361 - loss: 0.7032 - val_accuracy: 0.6099 - val_loss: 0.6826\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6169 - loss: 0.6722 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5513 - loss: 36.2154 - val_accuracy: 0.5874 - val_loss: 27.2914\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5891 - loss: 21.9166 - val_accuracy: 0.5919 - val_loss: 32.2616\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5828 - loss: 23.8786 - val_accuracy: 0.5919 - val_loss: 14.7834\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5887 - loss: 19.7471 - val_accuracy: 0.5874 - val_loss: 4.8776\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5813 - loss: 17.7983 - val_accuracy: 0.6099 - val_loss: 7.0220\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6070 - loss: 17.8292 - val_accuracy: 0.5919 - val_loss: 14.5184\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5861 - loss: 13.8610 - val_accuracy: 0.5919 - val_loss: 12.8443\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5860 - loss: 15.0697 - val_accuracy: 0.5919 - val_loss: 10.6539\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5778 - loss: 10.8607 - val_accuracy: 0.5919 - val_loss: 15.3125\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5993 - loss: 13.9791 - val_accuracy: 0.5919 - val_loss: 12.4720\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5540 - loss: 11.0741 - val_accuracy: 0.5919 - val_loss: 12.8611\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5563 - loss: 10.5539 - val_accuracy: 0.5919 - val_loss: 14.7181\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5677 - loss: 11.5844 - val_accuracy: 0.5919 - val_loss: 10.5558\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5954 - loss: 7.6006 - val_accuracy: 0.5919 - val_loss: 9.6677\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5842 - loss: 8.6053 - val_accuracy: 0.5919 - val_loss: 8.4802\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5934 - loss: 6.9503 - val_accuracy: 0.5964 - val_loss: 6.0937\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5741 - loss: 9.8362 - val_accuracy: 0.5919 - val_loss: 8.6598\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5912 - loss: 6.0523 - val_accuracy: 0.5964 - val_loss: 4.8782\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5986 - loss: 5.5327 - val_accuracy: 0.5964 - val_loss: 4.8802\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 4.6889 - val_accuracy: 0.5964 - val_loss: 4.3470\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6042 - loss: 3.6947 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3939 - loss: 47.6869 - val_accuracy: 0.4081 - val_loss: 4.3701\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5852 - loss: 3.7195 - val_accuracy: 0.3857 - val_loss: 2.5672\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5167 - loss: 2.7038 - val_accuracy: 0.5650 - val_loss: 0.9983\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5284 - loss: 2.6506 - val_accuracy: 0.5695 - val_loss: 1.0661\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5438 - loss: 1.8431 - val_accuracy: 0.5695 - val_loss: 1.0539\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5686 - loss: 1.8344 - val_accuracy: 0.5740 - val_loss: 1.1944\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5903 - loss: 1.6052 - val_accuracy: 0.5919 - val_loss: 1.0263\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5325 - loss: 1.7336 - val_accuracy: 0.5740 - val_loss: 0.8938\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5404 - loss: 1.6957 - val_accuracy: 0.5516 - val_loss: 0.7503\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5632 - loss: 1.3585 - val_accuracy: 0.5964 - val_loss: 0.8973\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5349 - loss: 1.6566 - val_accuracy: 0.6009 - val_loss: 1.1205\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5277 - loss: 1.6257 - val_accuracy: 0.5919 - val_loss: 0.7192\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5757 - loss: 1.2988 - val_accuracy: 0.5830 - val_loss: 0.7411\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5719 - loss: 1.1957 - val_accuracy: 0.6054 - val_loss: 0.8344\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5543 - loss: 1.2554 - val_accuracy: 0.4260 - val_loss: 0.9817\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5570 - loss: 1.2033 - val_accuracy: 0.6054 - val_loss: 0.8380\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5967 - loss: 1.0680 - val_accuracy: 0.5919 - val_loss: 0.8455\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 1.1442 - val_accuracy: 0.5874 - val_loss: 0.8493\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5595 - loss: 1.4123 - val_accuracy: 0.4439 - val_loss: 0.8567\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6057 - loss: 1.2053 - val_accuracy: 0.4933 - val_loss: 0.8321\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4886 - loss: 0.8747 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4604 - loss: 11.1217 - val_accuracy: 0.5919 - val_loss: 1.1765\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4684 - loss: 2.1550 - val_accuracy: 0.4395 - val_loss: 1.0033\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4639 - loss: 1.7413 - val_accuracy: 0.5919 - val_loss: 0.7362\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5310 - loss: 1.5657 - val_accuracy: 0.4215 - val_loss: 0.8662\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5254 - loss: 1.6241 - val_accuracy: 0.4305 - val_loss: 0.7753\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5271 - loss: 1.4592 - val_accuracy: 0.3946 - val_loss: 0.8313\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5603 - loss: 1.3758 - val_accuracy: 0.4081 - val_loss: 0.8360\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5579 - loss: 1.3781 - val_accuracy: 0.4126 - val_loss: 1.3805\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5147 - loss: 1.1809 - val_accuracy: 0.5605 - val_loss: 0.6871\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5399 - loss: 1.2292 - val_accuracy: 0.3946 - val_loss: 0.7651\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5867 - loss: 1.0515 - val_accuracy: 0.4081 - val_loss: 1.2601\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5123 - loss: 1.2095 - val_accuracy: 0.3812 - val_loss: 0.7351\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5838 - loss: 1.0250 - val_accuracy: 0.6009 - val_loss: 0.6926\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5484 - loss: 0.9769 - val_accuracy: 0.5830 - val_loss: 0.6803\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5677 - loss: 0.9593 - val_accuracy: 0.4081 - val_loss: 0.7194\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 0.9493 - val_accuracy: 0.6009 - val_loss: 0.6940\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5694 - loss: 0.9916 - val_accuracy: 0.3991 - val_loss: 0.7079\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5720 - loss: 0.9059 - val_accuracy: 0.6099 - val_loss: 0.7185\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5858 - loss: 0.9059 - val_accuracy: 0.5785 - val_loss: 0.6633\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5927 - loss: 0.8712 - val_accuracy: 0.5874 - val_loss: 0.6576\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6273 - loss: 0.6412 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.0005, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4768 - loss: 215.0530 - val_accuracy: 0.5919 - val_loss: 54.0168\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 39.3745 - val_accuracy: 0.6009 - val_loss: 13.0058\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5777 - loss: 27.3904 - val_accuracy: 0.6054 - val_loss: 8.3529\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5751 - loss: 22.1512 - val_accuracy: 0.6099 - val_loss: 5.2526\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5677 - loss: 23.9127 - val_accuracy: 0.6054 - val_loss: 6.7793\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5768 - loss: 20.7717 - val_accuracy: 0.5919 - val_loss: 15.3353\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5975 - loss: 21.1372 - val_accuracy: 0.6054 - val_loss: 8.1543\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5780 - loss: 18.0645 - val_accuracy: 0.3767 - val_loss: 31.5996\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5433 - loss: 20.9324 - val_accuracy: 0.6054 - val_loss: 9.1527\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5707 - loss: 20.1971 - val_accuracy: 0.5650 - val_loss: 11.0023\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 14.5379 - val_accuracy: 0.6143 - val_loss: 8.4516\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 12.8760 - val_accuracy: 0.5964 - val_loss: 10.0186\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5793 - loss: 14.9220 - val_accuracy: 0.6188 - val_loss: 6.3624\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6206 - loss: 11.6412 - val_accuracy: 0.5740 - val_loss: 10.8489\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5684 - loss: 12.7719 - val_accuracy: 0.6099 - val_loss: 5.2248\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5599 - loss: 11.1492 - val_accuracy: 0.6188 - val_loss: 4.1712\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6082 - loss: 11.2524 - val_accuracy: 0.5919 - val_loss: 14.1103\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6171 - loss: 12.2041 - val_accuracy: 0.6143 - val_loss: 4.4374\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6144 - loss: 10.0762 - val_accuracy: 0.4978 - val_loss: 8.3845\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5414 - loss: 10.3687 - val_accuracy: 0.6233 - val_loss: 4.5524\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6445 - loss: 4.1101 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5764 - loss: 12.6999 - val_accuracy: 0.5919 - val_loss: 3.0225\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5948 - loss: 4.8732 - val_accuracy: 0.5740 - val_loss: 1.1969\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6252 - loss: 3.0182 - val_accuracy: 0.3946 - val_loss: 2.5382\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5979 - loss: 2.8874 - val_accuracy: 0.4126 - val_loss: 5.0386\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6021 - loss: 2.7691 - val_accuracy: 0.4126 - val_loss: 8.5523\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5911 - loss: 2.3988 - val_accuracy: 0.4081 - val_loss: 5.8206\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6027 - loss: 2.3748 - val_accuracy: 0.4081 - val_loss: 6.1524\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 1.9577 - val_accuracy: 0.4081 - val_loss: 5.5601\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6375 - loss: 1.7513 - val_accuracy: 0.4081 - val_loss: 5.3997\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5913 - loss: 1.8776 - val_accuracy: 0.4081 - val_loss: 5.9147\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 1.8026 - val_accuracy: 0.4081 - val_loss: 4.9939\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6117 - loss: 1.6673 - val_accuracy: 0.4081 - val_loss: 5.3379\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5950 - loss: 1.5944 - val_accuracy: 0.4126 - val_loss: 4.0411\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6049 - loss: 1.5771 - val_accuracy: 0.4081 - val_loss: 3.9250\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6093 - loss: 1.4039 - val_accuracy: 0.4081 - val_loss: 5.0809\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6089 - loss: 1.3144 - val_accuracy: 0.4081 - val_loss: 3.7534\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6244 - loss: 1.3592 - val_accuracy: 0.4081 - val_loss: 4.8739\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6269 - loss: 1.2911 - val_accuracy: 0.4126 - val_loss: 2.8599\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6421 - loss: 1.1880 - val_accuracy: 0.4081 - val_loss: 2.6838\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6340 - loss: 1.0910 - val_accuracy: 0.4081 - val_loss: 2.7180\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4088 - loss: 2.6717 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4860 - loss: 2.4784 - val_accuracy: 0.5919 - val_loss: 0.7448\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5359 - loss: 1.8002 - val_accuracy: 0.6099 - val_loss: 0.7069\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5992 - loss: 1.5108 - val_accuracy: 0.3991 - val_loss: 0.9489\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5559 - loss: 1.2926 - val_accuracy: 0.4350 - val_loss: 0.8446\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5768 - loss: 1.2946 - val_accuracy: 0.4081 - val_loss: 1.2050\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5384 - loss: 1.1528 - val_accuracy: 0.6188 - val_loss: 0.6684\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5690 - loss: 0.9202 - val_accuracy: 0.6099 - val_loss: 0.6635\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.9590 - val_accuracy: 0.6054 - val_loss: 0.6847\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5632 - loss: 0.8614 - val_accuracy: 0.6278 - val_loss: 0.6542\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5599 - loss: 0.8200 - val_accuracy: 0.6188 - val_loss: 0.6607\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5358 - loss: 0.8546 - val_accuracy: 0.5919 - val_loss: 0.7153\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5692 - loss: 0.8192 - val_accuracy: 0.5964 - val_loss: 0.6994\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5937 - loss: 0.8232 - val_accuracy: 0.6188 - val_loss: 0.6604\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5922 - loss: 0.7230 - val_accuracy: 0.5919 - val_loss: 0.7106\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5877 - loss: 0.7424 - val_accuracy: 0.6143 - val_loss: 0.6681\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6021 - loss: 0.7319 - val_accuracy: 0.6143 - val_loss: 0.6678\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6088 - loss: 0.6674 - val_accuracy: 0.6009 - val_loss: 0.6773\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6079 - loss: 0.6887 - val_accuracy: 0.6054 - val_loss: 0.6714\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6060 - loss: 0.7520 - val_accuracy: 0.6099 - val_loss: 0.6656\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.6787 - val_accuracy: 0.5964 - val_loss: 0.7111\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5977 - loss: 0.7081 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5827 - loss: 60.5404 - val_accuracy: 0.3812 - val_loss: 61.4137\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5909 - loss: 29.0326 - val_accuracy: 0.6233 - val_loss: 18.3151\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5616 - loss: 31.3090 - val_accuracy: 0.4484 - val_loss: 36.3222\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5516 - loss: 29.8925 - val_accuracy: 0.5112 - val_loss: 29.6221\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5685 - loss: 29.0339 - val_accuracy: 0.3991 - val_loss: 42.5550\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5467 - loss: 27.1177 - val_accuracy: 0.4664 - val_loss: 25.3847\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5583 - loss: 23.3700 - val_accuracy: 0.5964 - val_loss: 15.3965\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5948 - loss: 23.6387 - val_accuracy: 0.4215 - val_loss: 27.3158\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5979 - loss: 18.8870 - val_accuracy: 0.6413 - val_loss: 11.3062\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 16.4281 - val_accuracy: 0.4484 - val_loss: 31.3437\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6144 - loss: 14.3335 - val_accuracy: 0.4529 - val_loss: 24.9086\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5799 - loss: 14.9971 - val_accuracy: 0.5695 - val_loss: 16.5470\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6190 - loss: 13.6285 - val_accuracy: 0.6143 - val_loss: 9.8769\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5760 - loss: 15.5854 - val_accuracy: 0.6009 - val_loss: 13.0626\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5711 - loss: 18.1524 - val_accuracy: 0.6323 - val_loss: 8.9611\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5966 - loss: 13.6111 - val_accuracy: 0.6278 - val_loss: 11.6391\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5966 - loss: 11.2858 - val_accuracy: 0.6143 - val_loss: 12.1922\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6212 - loss: 9.0318 - val_accuracy: 0.6547 - val_loss: 6.6191\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6181 - loss: 8.9244 - val_accuracy: 0.6547 - val_loss: 6.1623\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6526 - loss: 7.4112 - val_accuracy: 0.6457 - val_loss: 8.1056\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6740 - loss: 7.1879 \n",
      "Training model with: layers = 2, dropout = 0.2, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4757 - loss: 5.8133 - val_accuracy: 0.5874 - val_loss: 6.5087\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4738 - loss: 3.9384 - val_accuracy: 0.5874 - val_loss: 3.4715\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4925 - loss: 3.7527 - val_accuracy: 0.5874 - val_loss: 1.3414\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5517 - loss: 2.5729 - val_accuracy: 0.5964 - val_loss: 0.6707\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5631 - loss: 2.1732 - val_accuracy: 0.4126 - val_loss: 1.7947\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5836 - loss: 2.0239 - val_accuracy: 0.4126 - val_loss: 2.1270\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6253 - loss: 1.6430 - val_accuracy: 0.4081 - val_loss: 4.0377\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6033 - loss: 2.0921 - val_accuracy: 0.4170 - val_loss: 2.2560\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6142 - loss: 1.6670 - val_accuracy: 0.4170 - val_loss: 2.2856\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5869 - loss: 1.6078 - val_accuracy: 0.4081 - val_loss: 2.8336\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5906 - loss: 1.6487 - val_accuracy: 0.4170 - val_loss: 2.5891\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5577 - loss: 1.8118 - val_accuracy: 0.4170 - val_loss: 2.4476\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6109 - loss: 1.6163 - val_accuracy: 0.4081 - val_loss: 2.4358\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5975 - loss: 1.3468 - val_accuracy: 0.4081 - val_loss: 2.1604\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6084 - loss: 1.2518 - val_accuracy: 0.4081 - val_loss: 2.8523\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 1.3182 - val_accuracy: 0.4081 - val_loss: 2.0135\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5985 - loss: 1.1959 - val_accuracy: 0.4081 - val_loss: 2.2264\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6392 - loss: 1.4741 - val_accuracy: 0.4081 - val_loss: 1.9439\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6354 - loss: 1.1239 - val_accuracy: 0.4081 - val_loss: 2.0072\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6186 - loss: 1.1221 - val_accuracy: 0.4170 - val_loss: 1.5751\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4181 - loss: 1.5886 \n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3817 - loss: 23.8150 - val_accuracy: 0.5919 - val_loss: 1.4189\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5274 - loss: 3.1955 - val_accuracy: 0.4619 - val_loss: 0.9255\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4886 - loss: 2.0105 - val_accuracy: 0.6143 - val_loss: 0.8216\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5456 - loss: 1.6877 - val_accuracy: 0.6009 - val_loss: 0.9804\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5458 - loss: 1.5582 - val_accuracy: 0.5919 - val_loss: 1.1305\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5341 - loss: 1.5507 - val_accuracy: 0.5919 - val_loss: 1.0556\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5340 - loss: 1.6614 - val_accuracy: 0.5919 - val_loss: 0.9156\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 1.2373 - val_accuracy: 0.5964 - val_loss: 1.0548\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5527 - loss: 1.4595 - val_accuracy: 0.6143 - val_loss: 0.7069\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5308 - loss: 1.2447 - val_accuracy: 0.5919 - val_loss: 1.2576\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5325 - loss: 1.4639 - val_accuracy: 0.5964 - val_loss: 0.8637\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5593 - loss: 1.2677 - val_accuracy: 0.5964 - val_loss: 0.8846\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5683 - loss: 1.1037 - val_accuracy: 0.6054 - val_loss: 0.7844\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5620 - loss: 1.1008 - val_accuracy: 0.6099 - val_loss: 0.7146\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6039 - loss: 1.0269 - val_accuracy: 0.5919 - val_loss: 0.9543\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5838 - loss: 1.1669 - val_accuracy: 0.6009 - val_loss: 0.7420\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5473 - loss: 0.9998 - val_accuracy: 0.5919 - val_loss: 0.7963\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5994 - loss: 0.9876 - val_accuracy: 0.5919 - val_loss: 0.9036\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5527 - loss: 1.0193 - val_accuracy: 0.5919 - val_loss: 0.9162\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5855 - loss: 0.9236 - val_accuracy: 0.5919 - val_loss: 0.8365\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5870 - loss: 0.8532 \n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4484 - loss: 404.6368 - val_accuracy: 0.5919 - val_loss: 92.4562\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6329 - loss: 54.9630 - val_accuracy: 0.5919 - val_loss: 24.1283\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6021 - loss: 33.7408 - val_accuracy: 0.6009 - val_loss: 15.9334\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5686 - loss: 33.1395 - val_accuracy: 0.6054 - val_loss: 12.9448\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5967 - loss: 28.7094 - val_accuracy: 0.6099 - val_loss: 15.7050\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6015 - loss: 24.9647 - val_accuracy: 0.5964 - val_loss: 15.1576\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5940 - loss: 27.6088 - val_accuracy: 0.5740 - val_loss: 17.6866\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6047 - loss: 25.0682 - val_accuracy: 0.6054 - val_loss: 16.6467\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6251 - loss: 17.0734 - val_accuracy: 0.6323 - val_loss: 12.4721\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6181 - loss: 17.5771 - val_accuracy: 0.6413 - val_loss: 11.3084\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5939 - loss: 17.2511 - val_accuracy: 0.6233 - val_loss: 13.4747\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6001 - loss: 16.3041 - val_accuracy: 0.5964 - val_loss: 14.0390\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6096 - loss: 14.6011 - val_accuracy: 0.5964 - val_loss: 12.5359\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5771 - loss: 14.5007 - val_accuracy: 0.6099 - val_loss: 9.4801\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 19.2287 - val_accuracy: 0.6009 - val_loss: 9.6077\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5940 - loss: 11.5217 - val_accuracy: 0.6368 - val_loss: 7.9933\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 8.5841 - val_accuracy: 0.6009 - val_loss: 8.5915\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6262 - loss: 8.4281 - val_accuracy: 0.6323 - val_loss: 6.1226\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6076 - loss: 9.1928 - val_accuracy: 0.5964 - val_loss: 14.7299\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6313 - loss: 9.4503 - val_accuracy: 0.6368 - val_loss: 6.5400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6393 - loss: 6.2643 \n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4451 - loss: 9.0843 - val_accuracy: 0.5874 - val_loss: 2.1170\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4473 - loss: 4.0429 - val_accuracy: 0.5919 - val_loss: 1.7486\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5176 - loss: 2.6941 - val_accuracy: 0.5919 - val_loss: 1.6400\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5583 - loss: 2.5949 - val_accuracy: 0.5919 - val_loss: 1.0265\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5399 - loss: 2.5721 - val_accuracy: 0.5785 - val_loss: 0.7135\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5209 - loss: 2.0251 - val_accuracy: 0.5650 - val_loss: 0.8188\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5444 - loss: 2.2253 - val_accuracy: 0.4305 - val_loss: 1.2767\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5653 - loss: 1.7770 - val_accuracy: 0.5426 - val_loss: 0.7739\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5998 - loss: 1.5702 - val_accuracy: 0.4215 - val_loss: 1.6199\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 1.5411 - val_accuracy: 0.4350 - val_loss: 1.1980\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 1.2451 - val_accuracy: 0.4215 - val_loss: 2.2146\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5974 - loss: 1.3793 - val_accuracy: 0.4215 - val_loss: 1.9105\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6175 - loss: 1.2358 - val_accuracy: 0.4215 - val_loss: 1.9903\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5728 - loss: 1.3248 - val_accuracy: 0.4260 - val_loss: 1.3987\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5874 - loss: 1.2539 - val_accuracy: 0.4170 - val_loss: 2.0291\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5822 - loss: 1.2612 - val_accuracy: 0.4215 - val_loss: 1.6656\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 1.1598 - val_accuracy: 0.4215 - val_loss: 1.3552\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5979 - loss: 1.1961 - val_accuracy: 0.4126 - val_loss: 1.6774\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 1.1234 - val_accuracy: 0.4215 - val_loss: 1.2420\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5797 - loss: 1.1302 - val_accuracy: 0.4170 - val_loss: 1.5391\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4181 - loss: 1.5528 \n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4541 - loss: 7.8000 - val_accuracy: 0.4036 - val_loss: 1.5016\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5088 - loss: 2.6709 - val_accuracy: 0.6323 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5500 - loss: 2.0512 - val_accuracy: 0.6143 - val_loss: 0.7240\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5885 - loss: 2.0083 - val_accuracy: 0.6009 - val_loss: 0.7877\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5513 - loss: 2.2585 - val_accuracy: 0.6188 - val_loss: 0.7158\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5532 - loss: 1.8738 - val_accuracy: 0.5919 - val_loss: 1.4274\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5712 - loss: 1.5452 - val_accuracy: 0.6009 - val_loss: 0.7353\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4896 - loss: 1.5769 - val_accuracy: 0.5919 - val_loss: 1.5073\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5398 - loss: 1.5744 - val_accuracy: 0.6009 - val_loss: 0.8528\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5752 - loss: 1.3163 - val_accuracy: 0.5919 - val_loss: 1.1052\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5829 - loss: 1.3083 - val_accuracy: 0.6009 - val_loss: 0.7131\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5534 - loss: 1.2081 - val_accuracy: 0.5919 - val_loss: 1.1393\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5756 - loss: 1.2118 - val_accuracy: 0.5919 - val_loss: 1.1525\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5693 - loss: 1.0649 - val_accuracy: 0.5919 - val_loss: 0.9007\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5738 - loss: 1.0303 - val_accuracy: 0.5919 - val_loss: 0.8593\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5878 - loss: 0.9944 - val_accuracy: 0.5964 - val_loss: 0.7745\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5568 - loss: 0.9211 - val_accuracy: 0.5964 - val_loss: 0.7400\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5927 - loss: 0.8778 - val_accuracy: 0.5919 - val_loss: 1.0623\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5927 - loss: 0.8653 - val_accuracy: 0.5919 - val_loss: 0.7904\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5847 - loss: 0.8837 - val_accuracy: 0.6009 - val_loss: 0.7100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6012 - loss: 0.7198 \n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.0005, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5855 - loss: 59.3744 - val_accuracy: 0.6188 - val_loss: 13.6079\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 44.0407 - val_accuracy: 0.5874 - val_loss: 23.5145\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 38.2559 - val_accuracy: 0.6143 - val_loss: 12.3763\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5579 - loss: 38.7472 - val_accuracy: 0.6009 - val_loss: 16.9760\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5902 - loss: 29.0199 - val_accuracy: 0.5964 - val_loss: 24.6056\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5872 - loss: 28.9394 - val_accuracy: 0.5919 - val_loss: 20.8588\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 31.9683 - val_accuracy: 0.6009 - val_loss: 21.4792\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5860 - loss: 24.0886 - val_accuracy: 0.5919 - val_loss: 35.6848\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5860 - loss: 28.0060 - val_accuracy: 0.5964 - val_loss: 27.0117\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5933 - loss: 22.2875 - val_accuracy: 0.6009 - val_loss: 22.6059\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5757 - loss: 20.2395 - val_accuracy: 0.6009 - val_loss: 21.9077\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5835 - loss: 18.4635 - val_accuracy: 0.5919 - val_loss: 21.8101\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5854 - loss: 14.7301 - val_accuracy: 0.6009 - val_loss: 17.9003\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5723 - loss: 16.3898 - val_accuracy: 0.6143 - val_loss: 17.0128\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5676 - loss: 14.1015 - val_accuracy: 0.6009 - val_loss: 20.0898\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6231 - loss: 11.6882 - val_accuracy: 0.5964 - val_loss: 21.3569\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6007 - loss: 12.3140 - val_accuracy: 0.6009 - val_loss: 23.6231\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6003 - loss: 10.9353 - val_accuracy: 0.6143 - val_loss: 14.7739\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5775 - loss: 10.6754 - val_accuracy: 0.6143 - val_loss: 14.5684\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5942 - loss: 8.6818 - val_accuracy: 0.6099 - val_loss: 14.3777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6234 - loss: 12.6670\n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4977 - loss: 5.8729 - val_accuracy: 0.5830 - val_loss: 3.5773\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5093 - loss: 4.3702 - val_accuracy: 0.5067 - val_loss: 2.1484\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5780 - loss: 3.1186 - val_accuracy: 0.4126 - val_loss: 4.1118\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5696 - loss: 2.7351 - val_accuracy: 0.4081 - val_loss: 3.7945\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6068 - loss: 2.4028 - val_accuracy: 0.4081 - val_loss: 4.9271\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6055 - loss: 2.6486 - val_accuracy: 0.4081 - val_loss: 6.0901\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6526 - loss: 1.9520 - val_accuracy: 0.4081 - val_loss: 2.9510\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5876 - loss: 2.2001 - val_accuracy: 0.4081 - val_loss: 5.4419\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6109 - loss: 1.9050 - val_accuracy: 0.4081 - val_loss: 4.9711\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6175 - loss: 1.6042 - val_accuracy: 0.4126 - val_loss: 4.5453\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6547 - loss: 1.5263 - val_accuracy: 0.4126 - val_loss: 5.3114\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5943 - loss: 1.8304 - val_accuracy: 0.4126 - val_loss: 4.4042\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6176 - loss: 1.5706 - val_accuracy: 0.4126 - val_loss: 6.2989\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6269 - loss: 1.5809 - val_accuracy: 0.4081 - val_loss: 4.5170\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6162 - loss: 1.6048 - val_accuracy: 0.4081 - val_loss: 5.4118\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 1.5434 - val_accuracy: 0.4081 - val_loss: 4.5189\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6323 - loss: 1.3105 - val_accuracy: 0.4081 - val_loss: 4.0643\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5986 - loss: 1.2880 - val_accuracy: 0.4081 - val_loss: 3.5016\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6293 - loss: 1.3498 - val_accuracy: 0.4081 - val_loss: 4.6844\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6151 - loss: 1.2115 - val_accuracy: 0.4081 - val_loss: 4.0790\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3950 - loss: 4.3149 \n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4476 - loss: 10.2094 - val_accuracy: 0.5919 - val_loss: 1.9132\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4982 - loss: 2.3259 - val_accuracy: 0.6009 - val_loss: 1.0487\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5861 - loss: 1.8367 - val_accuracy: 0.5919 - val_loss: 1.0929\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5214 - loss: 1.9694 - val_accuracy: 0.6099 - val_loss: 0.7707\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5688 - loss: 1.7567 - val_accuracy: 0.5919 - val_loss: 1.1990\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5837 - loss: 1.4898 - val_accuracy: 0.5919 - val_loss: 1.3661\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5936 - loss: 1.3560 - val_accuracy: 0.5919 - val_loss: 1.0362\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5295 - loss: 1.4390 - val_accuracy: 0.5919 - val_loss: 1.5061\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5650 - loss: 1.2820 - val_accuracy: 0.5919 - val_loss: 1.3210\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5797 - loss: 1.1293 - val_accuracy: 0.5919 - val_loss: 1.2422\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5242 - loss: 1.2743 - val_accuracy: 0.5919 - val_loss: 1.0890\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6200 - loss: 0.9496 - val_accuracy: 0.5919 - val_loss: 1.1634\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5517 - loss: 0.9499 - val_accuracy: 0.5919 - val_loss: 1.4757\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5994 - loss: 1.0597 - val_accuracy: 0.5919 - val_loss: 1.2044\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5490 - loss: 0.9649 - val_accuracy: 0.5919 - val_loss: 1.0446\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 0.8779 - val_accuracy: 0.5919 - val_loss: 1.4905\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5656 - loss: 0.9428 - val_accuracy: 0.5964 - val_loss: 1.0185\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6068 - loss: 0.8461 - val_accuracy: 0.5919 - val_loss: 1.0663\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5770 - loss: 0.8685 - val_accuracy: 0.5964 - val_loss: 0.9275\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5653 - loss: 0.9042 - val_accuracy: 0.5919 - val_loss: 1.1100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5870 - loss: 1.1194 \n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5456 - loss: 52.8474 - val_accuracy: 0.6143 - val_loss: 24.0419\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5677 - loss: 41.4904 - val_accuracy: 0.3722 - val_loss: 40.7721\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5472 - loss: 34.1250 - val_accuracy: 0.6099 - val_loss: 15.4800\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6173 - loss: 29.1220 - val_accuracy: 0.5964 - val_loss: 14.8646\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5457 - loss: 26.8120 - val_accuracy: 0.5919 - val_loss: 20.7688\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5846 - loss: 29.3579 - val_accuracy: 0.4260 - val_loss: 6.7130\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5918 - loss: 19.0744 - val_accuracy: 0.5874 - val_loss: 14.8308\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6059 - loss: 18.5204 - val_accuracy: 0.4395 - val_loss: 6.7367\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5829 - loss: 16.0184 - val_accuracy: 0.5919 - val_loss: 13.1102\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5852 - loss: 13.5035 - val_accuracy: 0.6143 - val_loss: 6.2500\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5630 - loss: 14.8989 - val_accuracy: 0.6099 - val_loss: 13.0028\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5768 - loss: 12.8445 - val_accuracy: 0.6143 - val_loss: 8.4837\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6339 - loss: 10.9448 - val_accuracy: 0.6143 - val_loss: 6.8078\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5801 - loss: 11.3571 - val_accuracy: 0.6143 - val_loss: 8.5539\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5754 - loss: 11.2529 - val_accuracy: 0.6278 - val_loss: 6.0778\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5616 - loss: 10.1986 - val_accuracy: 0.6188 - val_loss: 9.6692\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5901 - loss: 8.4768 - val_accuracy: 0.6188 - val_loss: 8.0467\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6296 - loss: 8.4462 - val_accuracy: 0.6099 - val_loss: 10.5876\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 8.1087 - val_accuracy: 0.6099 - val_loss: 9.9030\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5787 - loss: 8.4057 - val_accuracy: 0.6054 - val_loss: 5.7063\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5949 - loss: 5.4599 \n",
      "Training model with: layers = 2, dropout = 0.3, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4641 - loss: 9.9135 - val_accuracy: 0.5919 - val_loss: 4.7099\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5268 - loss: 6.5616 - val_accuracy: 0.5830 - val_loss: 1.5639\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4893 - loss: 5.5475 - val_accuracy: 0.4170 - val_loss: 1.8435\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5523 - loss: 4.3116 - val_accuracy: 0.4126 - val_loss: 3.2135\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5568 - loss: 3.6652 - val_accuracy: 0.4574 - val_loss: 1.2781\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6195 - loss: 3.1999 - val_accuracy: 0.4126 - val_loss: 3.9465\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5814 - loss: 2.9064 - val_accuracy: 0.4081 - val_loss: 4.7700\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6127 - loss: 2.7399 - val_accuracy: 0.4126 - val_loss: 4.5482\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6256 - loss: 2.8836 - val_accuracy: 0.4081 - val_loss: 6.6851\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6056 - loss: 2.5834 - val_accuracy: 0.4126 - val_loss: 4.9993\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6263 - loss: 2.3234 - val_accuracy: 0.4126 - val_loss: 6.2094\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6408 - loss: 1.8532 - val_accuracy: 0.4126 - val_loss: 6.2558\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6238 - loss: 1.9924 - val_accuracy: 0.4081 - val_loss: 4.6500\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6414 - loss: 1.9340 - val_accuracy: 0.4126 - val_loss: 6.0526\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6041 - loss: 2.0048 - val_accuracy: 0.4170 - val_loss: 3.9095\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6535 - loss: 1.5932 - val_accuracy: 0.4081 - val_loss: 6.5905\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6225 - loss: 1.6502 - val_accuracy: 0.4081 - val_loss: 5.3875\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6389 - loss: 1.7096 - val_accuracy: 0.4081 - val_loss: 5.5732\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 1.6742 - val_accuracy: 0.4081 - val_loss: 4.2266\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6610 - loss: 1.5066 - val_accuracy: 0.4081 - val_loss: 5.8617\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3950 - loss: 6.3665 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5085 - loss: 23.9589 - val_accuracy: 0.4081 - val_loss: 6.6525\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4944 - loss: 3.7791 - val_accuracy: 0.5830 - val_loss: 1.2135\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5778 - loss: 2.2803 - val_accuracy: 0.5740 - val_loss: 0.8203\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5525 - loss: 2.1509 - val_accuracy: 0.5964 - val_loss: 0.8491\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5712 - loss: 2.0835 - val_accuracy: 0.4260 - val_loss: 0.9572\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5655 - loss: 2.0082 - val_accuracy: 0.5964 - val_loss: 0.7201\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 1.5241 - val_accuracy: 0.3946 - val_loss: 1.7324\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5732 - loss: 1.9362 - val_accuracy: 0.6188 - val_loss: 0.7694\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 1.5417 - val_accuracy: 0.6502 - val_loss: 0.7036\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5421 - loss: 1.5856 - val_accuracy: 0.5919 - val_loss: 1.7910\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 1.5156 - val_accuracy: 0.6368 - val_loss: 0.6826\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5244 - loss: 1.6774 - val_accuracy: 0.6143 - val_loss: 0.7905\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5870 - loss: 1.2966 - val_accuracy: 0.6099 - val_loss: 0.7691\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5877 - loss: 1.3692 - val_accuracy: 0.6413 - val_loss: 0.6939\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5911 - loss: 1.2111 - val_accuracy: 0.6502 - val_loss: 0.6655\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5563 - loss: 1.1652 - val_accuracy: 0.5919 - val_loss: 1.2944\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6026 - loss: 1.1608 - val_accuracy: 0.6099 - val_loss: 0.7081\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6042 - loss: 0.9751 - val_accuracy: 0.6054 - val_loss: 0.7482\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5881 - loss: 0.9807 - val_accuracy: 0.6009 - val_loss: 0.8328\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6088 - loss: 1.0353 - val_accuracy: 0.6323 - val_loss: 0.6587\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6630 - loss: 0.6382 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5775 - loss: 113.8089 - val_accuracy: 0.4215 - val_loss: 92.1371\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6004 - loss: 38.7065 - val_accuracy: 0.6143 - val_loss: 54.4949\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5773 - loss: 51.0145 - val_accuracy: 0.6009 - val_loss: 50.6306\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6100 - loss: 43.3029 - val_accuracy: 0.6278 - val_loss: 23.3016\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5917 - loss: 34.2549 - val_accuracy: 0.6278 - val_loss: 16.7430\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 31.9912 - val_accuracy: 0.6278 - val_loss: 18.0616\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5745 - loss: 33.2273 - val_accuracy: 0.6233 - val_loss: 17.3186\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6292 - loss: 20.2921 - val_accuracy: 0.5919 - val_loss: 53.8229\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 34.0152 - val_accuracy: 0.6233 - val_loss: 13.4276\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5637 - loss: 23.5025 - val_accuracy: 0.6323 - val_loss: 18.2632\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6057 - loss: 19.5833 - val_accuracy: 0.6233 - val_loss: 8.2939\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5421 - loss: 23.0415 - val_accuracy: 0.5919 - val_loss: 14.2538\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6003 - loss: 18.6707 - val_accuracy: 0.5874 - val_loss: 15.1540\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6022 - loss: 17.0282 - val_accuracy: 0.6278 - val_loss: 21.1210\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6011 - loss: 24.5852 - val_accuracy: 0.6278 - val_loss: 19.6841\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6063 - loss: 18.6536 - val_accuracy: 0.6054 - val_loss: 15.4837\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5889 - loss: 17.7259 - val_accuracy: 0.6233 - val_loss: 9.1788\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5748 - loss: 16.4952 - val_accuracy: 0.6188 - val_loss: 10.8439\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5777 - loss: 13.6815 - val_accuracy: 0.6009 - val_loss: 16.5756\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6013 - loss: 15.2154 - val_accuracy: 0.5874 - val_loss: 33.1345\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5943 - loss: 31.8154 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4485 - loss: 124.0312 - val_accuracy: 0.5874 - val_loss: 28.8976\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5315 - loss: 16.6476 - val_accuracy: 0.5874 - val_loss: 11.9832\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5565 - loss: 6.8159 - val_accuracy: 0.5336 - val_loss: 2.6962\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5372 - loss: 5.8798 - val_accuracy: 0.5874 - val_loss: 5.2082\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5383 - loss: 5.5545 - val_accuracy: 0.5874 - val_loss: 3.0287\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5280 - loss: 5.2872 - val_accuracy: 0.6099 - val_loss: 1.5310\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5783 - loss: 4.0203 - val_accuracy: 0.4081 - val_loss: 5.8164\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5314 - loss: 3.7353 - val_accuracy: 0.4081 - val_loss: 6.1068\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5903 - loss: 3.3062 - val_accuracy: 0.4081 - val_loss: 3.3016\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5978 - loss: 3.1126 - val_accuracy: 0.4215 - val_loss: 3.2505\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5898 - loss: 2.8230 - val_accuracy: 0.4036 - val_loss: 3.9365\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5931 - loss: 2.9151 - val_accuracy: 0.4081 - val_loss: 5.3164\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5519 - loss: 2.7824 - val_accuracy: 0.4081 - val_loss: 6.6682\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5767 - loss: 2.3848 - val_accuracy: 0.4081 - val_loss: 6.3159\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6415 - loss: 2.0190 - val_accuracy: 0.4081 - val_loss: 6.7346\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5734 - loss: 2.2744 - val_accuracy: 0.4036 - val_loss: 4.8471\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5518 - loss: 2.0731 - val_accuracy: 0.4036 - val_loss: 5.0370\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6119 - loss: 1.7539 - val_accuracy: 0.4081 - val_loss: 5.1779\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5982 - loss: 1.8319 - val_accuracy: 0.4081 - val_loss: 5.6232\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 1.8144 - val_accuracy: 0.4081 - val_loss: 4.4389\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4171 - loss: 4.1208 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5796 - loss: 10.0480 - val_accuracy: 0.6502 - val_loss: 1.1362\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 2.2199 - val_accuracy: 0.4215 - val_loss: 0.8488\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5792 - loss: 1.6018 - val_accuracy: 0.3946 - val_loss: 1.4582\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5315 - loss: 1.5344 - val_accuracy: 0.4933 - val_loss: 0.8198\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5593 - loss: 1.1830 - val_accuracy: 0.3946 - val_loss: 1.2711\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5888 - loss: 0.9655 - val_accuracy: 0.4888 - val_loss: 0.7196\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5941 - loss: 0.9928 - val_accuracy: 0.4126 - val_loss: 0.7813\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5578 - loss: 0.9553 - val_accuracy: 0.4215 - val_loss: 0.7641\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5700 - loss: 0.9232 - val_accuracy: 0.6143 - val_loss: 0.6551\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5857 - loss: 0.8373 - val_accuracy: 0.4126 - val_loss: 0.8123\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5831 - loss: 0.8592 - val_accuracy: 0.4439 - val_loss: 0.7434\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5815 - loss: 0.8502 - val_accuracy: 0.6054 - val_loss: 0.6677\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5781 - loss: 0.8328 - val_accuracy: 0.6188 - val_loss: 0.6664\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5966 - loss: 0.8005 - val_accuracy: 0.6368 - val_loss: 0.6402\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 0.7565 - val_accuracy: 0.6143 - val_loss: 0.6820\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5524 - loss: 0.8525 - val_accuracy: 0.6009 - val_loss: 0.7971\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5988 - loss: 0.7705 - val_accuracy: 0.6009 - val_loss: 0.6868\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6110 - loss: 0.7550 - val_accuracy: 0.6188 - val_loss: 0.6698\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5541 - loss: 0.8861 - val_accuracy: 0.6233 - val_loss: 0.6618\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6201 - loss: 0.7674 - val_accuracy: 0.5964 - val_loss: 0.7767\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5955 - loss: 0.7842 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.0005, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5604 - loss: 252.1915 - val_accuracy: 0.6009 - val_loss: 24.6061\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5691 - loss: 46.0079 - val_accuracy: 0.6009 - val_loss: 25.7978\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5592 - loss: 36.6874 - val_accuracy: 0.5919 - val_loss: 51.4146\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5515 - loss: 40.3256 - val_accuracy: 0.5919 - val_loss: 48.3020\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5469 - loss: 36.1773 - val_accuracy: 0.6188 - val_loss: 25.5626\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5601 - loss: 35.2527 - val_accuracy: 0.5919 - val_loss: 41.1182\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6059 - loss: 36.9831 - val_accuracy: 0.6188 - val_loss: 22.6449\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5512 - loss: 25.9004 - val_accuracy: 0.5874 - val_loss: 23.3194\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6444 - loss: 21.7962 - val_accuracy: 0.6054 - val_loss: 16.1307\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6328 - loss: 15.9306 - val_accuracy: 0.5919 - val_loss: 16.2963\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6182 - loss: 18.0113 - val_accuracy: 0.5919 - val_loss: 18.8702\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6303 - loss: 12.3996 - val_accuracy: 0.6054 - val_loss: 10.2210\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5723 - loss: 14.0567 - val_accuracy: 0.5874 - val_loss: 12.8987\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6094 - loss: 11.0195 - val_accuracy: 0.5874 - val_loss: 7.5600\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6568 - loss: 9.8175 - val_accuracy: 0.5964 - val_loss: 7.9641\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6452 - loss: 11.0633 - val_accuracy: 0.6188 - val_loss: 3.2036\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5906 - loss: 12.5112 - val_accuracy: 0.5919 - val_loss: 11.8679\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6131 - loss: 9.9353 - val_accuracy: 0.5919 - val_loss: 10.4708\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5819 - loss: 8.5783 - val_accuracy: 0.5874 - val_loss: 12.9740\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5661 - loss: 10.4458 - val_accuracy: 0.5964 - val_loss: 8.0268\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6002 - loss: 8.0429 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4926 - loss: 10.6471 - val_accuracy: 0.5919 - val_loss: 2.6351\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6002 - loss: 5.8908 - val_accuracy: 0.4081 - val_loss: 10.8400\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5863 - loss: 4.7037 - val_accuracy: 0.4081 - val_loss: 5.4910\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6300 - loss: 3.4849 - val_accuracy: 0.5874 - val_loss: 0.9070\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6026 - loss: 3.5190 - val_accuracy: 0.5964 - val_loss: 0.9681\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5431 - loss: 3.1010 - val_accuracy: 0.6009 - val_loss: 1.0988\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5767 - loss: 2.7036 - val_accuracy: 0.4260 - val_loss: 4.1376\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5939 - loss: 2.7110 - val_accuracy: 0.4126 - val_loss: 5.6470\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6075 - loss: 2.4352 - val_accuracy: 0.4978 - val_loss: 1.6884\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6132 - loss: 2.0821 - val_accuracy: 0.5919 - val_loss: 1.3712\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5764 - loss: 2.0992 - val_accuracy: 0.5022 - val_loss: 2.2908\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5753 - loss: 1.8815 - val_accuracy: 0.4126 - val_loss: 3.0940\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6113 - loss: 1.6465 - val_accuracy: 0.3991 - val_loss: 2.3760\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6016 - loss: 1.6987 - val_accuracy: 0.4126 - val_loss: 3.9464\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 1.5279 - val_accuracy: 0.3991 - val_loss: 2.1585\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6323 - loss: 1.3861 - val_accuracy: 0.4081 - val_loss: 4.8113\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5969 - loss: 1.2729 - val_accuracy: 0.5964 - val_loss: 0.7711\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6310 - loss: 1.1727 - val_accuracy: 0.4170 - val_loss: 2.8054\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6156 - loss: 1.0755 - val_accuracy: 0.4170 - val_loss: 3.1784\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 1.1250 - val_accuracy: 0.3857 - val_loss: 2.2526\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3774 - loss: 2.2315 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4651 - loss: 31.9975 - val_accuracy: 0.5471 - val_loss: 0.9129\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5285 - loss: 2.7662 - val_accuracy: 0.5874 - val_loss: 1.4214\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5017 - loss: 1.8366 - val_accuracy: 0.5919 - val_loss: 2.4372\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5174 - loss: 1.8436 - val_accuracy: 0.5919 - val_loss: 2.4176\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6066 - loss: 1.4975 - val_accuracy: 0.5919 - val_loss: 2.2661\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5583 - loss: 1.4714 - val_accuracy: 0.5919 - val_loss: 1.3599\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5606 - loss: 1.4069 - val_accuracy: 0.5919 - val_loss: 1.8547\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5410 - loss: 1.2558 - val_accuracy: 0.5919 - val_loss: 1.5733\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5706 - loss: 1.2303 - val_accuracy: 0.5919 - val_loss: 1.4246\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5588 - loss: 1.0786 - val_accuracy: 0.5919 - val_loss: 1.2171\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5258 - loss: 1.2618 - val_accuracy: 0.5919 - val_loss: 1.0413\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5602 - loss: 1.0603 - val_accuracy: 0.5919 - val_loss: 0.9048\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5557 - loss: 0.9492 - val_accuracy: 0.6009 - val_loss: 0.8004\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5486 - loss: 0.9533 - val_accuracy: 0.6143 - val_loss: 0.7680\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5252 - loss: 1.0004 - val_accuracy: 0.5964 - val_loss: 0.8654\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 0.8745 - val_accuracy: 0.5919 - val_loss: 0.7859\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5974 - loss: 0.8729 - val_accuracy: 0.5964 - val_loss: 0.7921\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5762 - loss: 0.8928 - val_accuracy: 0.5964 - val_loss: 0.6701\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5301 - loss: 0.9348 - val_accuracy: 0.5919 - val_loss: 0.9249\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6018 - loss: 0.8079 - val_accuracy: 0.6099 - val_loss: 0.7077\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6228 - loss: 0.7060 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6100 - loss: 619.5306 - val_accuracy: 0.4036 - val_loss: 161.9399\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5064 - loss: 153.9409 - val_accuracy: 0.5919 - val_loss: 76.7328\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5949 - loss: 97.5679 - val_accuracy: 0.4126 - val_loss: 82.4858\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5267 - loss: 108.8569 - val_accuracy: 0.5874 - val_loss: 84.1755\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5389 - loss: 97.6269 - val_accuracy: 0.5919 - val_loss: 80.6608\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5788 - loss: 81.3492 - val_accuracy: 0.5919 - val_loss: 52.4235\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6226 - loss: 56.2086 - val_accuracy: 0.5919 - val_loss: 65.7090\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5818 - loss: 71.8335 - val_accuracy: 0.5919 - val_loss: 164.0924\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5798 - loss: 80.4503 - val_accuracy: 0.5919 - val_loss: 63.2109\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6008 - loss: 59.2943 - val_accuracy: 0.5830 - val_loss: 20.4841\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5799 - loss: 49.9586 - val_accuracy: 0.5874 - val_loss: 26.5518\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5633 - loss: 57.1793 - val_accuracy: 0.5919 - val_loss: 31.7278\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5624 - loss: 49.1006 - val_accuracy: 0.5919 - val_loss: 21.2945\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5904 - loss: 41.2512 - val_accuracy: 0.5919 - val_loss: 36.3841\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6229 - loss: 37.7602 - val_accuracy: 0.5919 - val_loss: 28.1045\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5850 - loss: 37.8772 - val_accuracy: 0.5919 - val_loss: 44.7858\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6026 - loss: 36.2210 - val_accuracy: 0.5919 - val_loss: 36.9551\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6079 - loss: 36.4438 - val_accuracy: 0.5919 - val_loss: 19.3193\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5670 - loss: 30.1756 - val_accuracy: 0.5919 - val_loss: 29.4114\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6076 - loss: 26.4662 - val_accuracy: 0.5919 - val_loss: 21.1454\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5954 - loss: 21.5626 \n",
      "Training model with: layers = 3, dropout = 0.1, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5208 - loss: 7.3200 - val_accuracy: 0.4574 - val_loss: 2.5799\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5457 - loss: 4.4086 - val_accuracy: 0.4753 - val_loss: 2.4748\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5773 - loss: 3.3729 - val_accuracy: 0.5650 - val_loss: 1.7538\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5853 - loss: 2.9189 - val_accuracy: 0.4215 - val_loss: 5.7437\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5430 - loss: 3.0630 - val_accuracy: 0.3767 - val_loss: 2.8882\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5773 - loss: 2.3144 - val_accuracy: 0.4709 - val_loss: 2.2017\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5719 - loss: 2.3281 - val_accuracy: 0.4619 - val_loss: 1.8866\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 2.0358 - val_accuracy: 0.4126 - val_loss: 3.8423\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5942 - loss: 1.9699 - val_accuracy: 0.4036 - val_loss: 5.3103\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5933 - loss: 1.9307 - val_accuracy: 0.4215 - val_loss: 2.7395\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5946 - loss: 1.5720 - val_accuracy: 0.5202 - val_loss: 1.4966\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5704 - loss: 2.0328 - val_accuracy: 0.4350 - val_loss: 1.8839\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6522 - loss: 1.3955 - val_accuracy: 0.3946 - val_loss: 2.8410\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6136 - loss: 1.3025 - val_accuracy: 0.4888 - val_loss: 1.1611\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5966 - loss: 1.3445 - val_accuracy: 0.4081 - val_loss: 2.4377\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6192 - loss: 1.1223 - val_accuracy: 0.4126 - val_loss: 1.7036\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6584 - loss: 1.1900 - val_accuracy: 0.4439 - val_loss: 1.1792\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6307 - loss: 1.1548 - val_accuracy: 0.4215 - val_loss: 1.2408\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6303 - loss: 1.0392 - val_accuracy: 0.4260 - val_loss: 1.2186\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6298 - loss: 0.9861 - val_accuracy: 0.4350 - val_loss: 1.0797\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4398 - loss: 1.0291 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5103 - loss: 7.3675 - val_accuracy: 0.4260 - val_loss: 1.7486\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5338 - loss: 3.1736 - val_accuracy: 0.6009 - val_loss: 1.1627\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5648 - loss: 2.1026 - val_accuracy: 0.5874 - val_loss: 1.3636\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5628 - loss: 1.8172 - val_accuracy: 0.5919 - val_loss: 1.5654\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6012 - loss: 1.7186 - val_accuracy: 0.5919 - val_loss: 1.0578\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6079 - loss: 1.3026 - val_accuracy: 0.5919 - val_loss: 1.4286\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5963 - loss: 1.3321 - val_accuracy: 0.6099 - val_loss: 0.7121\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5647 - loss: 1.2856 - val_accuracy: 0.6009 - val_loss: 1.0361\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5414 - loss: 1.1673 - val_accuracy: 0.6188 - val_loss: 0.7580\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5904 - loss: 1.0126 - val_accuracy: 0.6457 - val_loss: 0.6645\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5943 - loss: 1.0094 - val_accuracy: 0.6009 - val_loss: 0.7588\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6105 - loss: 1.0343 - val_accuracy: 0.6099 - val_loss: 0.8373\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5972 - loss: 0.8680 - val_accuracy: 0.6323 - val_loss: 0.7297\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6251 - loss: 0.8206 - val_accuracy: 0.5874 - val_loss: 1.1602\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6145 - loss: 0.7983 - val_accuracy: 0.5919 - val_loss: 0.9890\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6248 - loss: 0.8283 - val_accuracy: 0.6233 - val_loss: 0.7162\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6426 - loss: 0.8472 - val_accuracy: 0.6278 - val_loss: 0.6943\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5732 - loss: 0.7703 - val_accuracy: 0.6009 - val_loss: 0.8125\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 0.7399 - val_accuracy: 0.5964 - val_loss: 0.9835\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5814 - loss: 0.7992 - val_accuracy: 0.6099 - val_loss: 0.6754\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6288 - loss: 0.6775 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5980 - loss: 181.2100 - val_accuracy: 0.5919 - val_loss: 10.2565\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5766 - loss: 62.9668 - val_accuracy: 0.5830 - val_loss: 61.7748\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5843 - loss: 49.6241 - val_accuracy: 0.5830 - val_loss: 51.4743\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5968 - loss: 44.4615 - val_accuracy: 0.5919 - val_loss: 48.7286\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5835 - loss: 37.3478 - val_accuracy: 0.5919 - val_loss: 54.3499\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6103 - loss: 32.4674 - val_accuracy: 0.5919 - val_loss: 28.2955\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6242 - loss: 22.8990 - val_accuracy: 0.5919 - val_loss: 24.7728\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5771 - loss: 25.2320 - val_accuracy: 0.5964 - val_loss: 22.3295\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5746 - loss: 22.8758 - val_accuracy: 0.6099 - val_loss: 8.9456\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5793 - loss: 19.3674 - val_accuracy: 0.5919 - val_loss: 25.4321\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6446 - loss: 13.1101 - val_accuracy: 0.5919 - val_loss: 30.9630\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6267 - loss: 12.1991 - val_accuracy: 0.5919 - val_loss: 16.6592\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6043 - loss: 11.6749 - val_accuracy: 0.5919 - val_loss: 10.9274\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6164 - loss: 8.2846 - val_accuracy: 0.5919 - val_loss: 13.0277\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6537 - loss: 7.5848 - val_accuracy: 0.6009 - val_loss: 6.5433\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5608 - loss: 8.3764 - val_accuracy: 0.3677 - val_loss: 13.4698\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5976 - loss: 8.4571 - val_accuracy: 0.4081 - val_loss: 14.6046\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5591 - loss: 6.8230 - val_accuracy: 0.4036 - val_loss: 6.4203\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5919 - loss: 6.3324 - val_accuracy: 0.5426 - val_loss: 3.8729\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6142 - loss: 6.8745 - val_accuracy: 0.5919 - val_loss: 7.6678\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5991 - loss: 6.5314 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5920 - loss: 41.5485 - val_accuracy: 0.5830 - val_loss: 3.0882\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5701 - loss: 7.8243 - val_accuracy: 0.4081 - val_loss: 12.2980\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6093 - loss: 3.5474 - val_accuracy: 0.4081 - val_loss: 10.2352\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5838 - loss: 4.0642 - val_accuracy: 0.4081 - val_loss: 7.8822\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 3.4827 - val_accuracy: 0.4170 - val_loss: 3.3122\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6279 - loss: 3.1162 - val_accuracy: 0.4081 - val_loss: 4.8369\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5870 - loss: 2.9593 - val_accuracy: 0.4081 - val_loss: 5.4405\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5980 - loss: 2.5952 - val_accuracy: 0.4081 - val_loss: 5.0376\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 2.0440 - val_accuracy: 0.4081 - val_loss: 3.3460\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6322 - loss: 2.1643 - val_accuracy: 0.4081 - val_loss: 2.7949\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 2.3191 - val_accuracy: 0.4081 - val_loss: 3.6628\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6308 - loss: 1.8525 - val_accuracy: 0.4170 - val_loss: 3.5743\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 1.6922 - val_accuracy: 0.4170 - val_loss: 3.5837\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5745 - loss: 1.7548 - val_accuracy: 0.4170 - val_loss: 3.2843\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6554 - loss: 1.2663 - val_accuracy: 0.4081 - val_loss: 3.1445\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6084 - loss: 1.4417 - val_accuracy: 0.4081 - val_loss: 3.2392\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6018 - loss: 1.2824 - val_accuracy: 0.4126 - val_loss: 2.9413\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 1.3721 - val_accuracy: 0.4170 - val_loss: 2.7155\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6002 - loss: 1.3157 - val_accuracy: 0.4170 - val_loss: 3.3397\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6541 - loss: 0.9581 - val_accuracy: 0.4170 - val_loss: 2.4452\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4181 - loss: 2.4603 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4812 - loss: 17.9815 - val_accuracy: 0.3901 - val_loss: 4.0116\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5385 - loss: 3.9600 - val_accuracy: 0.6368 - val_loss: 1.1955\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5659 - loss: 2.6573 - val_accuracy: 0.6188 - val_loss: 0.8593\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5829 - loss: 2.3316 - val_accuracy: 0.5874 - val_loss: 1.4973\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5515 - loss: 1.9893 - val_accuracy: 0.5964 - val_loss: 0.8239\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5340 - loss: 1.9863 - val_accuracy: 0.6054 - val_loss: 0.8816\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5533 - loss: 1.8652 - val_accuracy: 0.5964 - val_loss: 0.8894\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5377 - loss: 1.3913 - val_accuracy: 0.5874 - val_loss: 1.4199\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5699 - loss: 1.4125 - val_accuracy: 0.5874 - val_loss: 1.4248\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5256 - loss: 1.4700 - val_accuracy: 0.5874 - val_loss: 1.2663\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5473 - loss: 1.0705 - val_accuracy: 0.5874 - val_loss: 0.6941\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5737 - loss: 0.9948 - val_accuracy: 0.6233 - val_loss: 0.6674\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5798 - loss: 0.9146 - val_accuracy: 0.5874 - val_loss: 0.8512\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5609 - loss: 0.9291 - val_accuracy: 0.5919 - val_loss: 0.8280\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5782 - loss: 0.8440 - val_accuracy: 0.5919 - val_loss: 0.9812\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5695 - loss: 0.9133 - val_accuracy: 0.5919 - val_loss: 0.7877\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5370 - loss: 0.8649 - val_accuracy: 0.5919 - val_loss: 0.9905\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5815 - loss: 0.8502 - val_accuracy: 0.5919 - val_loss: 0.8344\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5574 - loss: 0.8354 - val_accuracy: 0.5919 - val_loss: 0.7244\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5793 - loss: 0.7955 - val_accuracy: 0.5919 - val_loss: 0.7745\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5870 - loss: 0.7946 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.0005, pooling = sum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5771 - loss: 106.2005 - val_accuracy: 0.4036 - val_loss: 101.4242\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5803 - loss: 90.5236 - val_accuracy: 0.5830 - val_loss: 32.3890\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5363 - loss: 49.9458 - val_accuracy: 0.5874 - val_loss: 38.4560\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6056 - loss: 31.7784 - val_accuracy: 0.5919 - val_loss: 58.0672\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5903 - loss: 34.1389 - val_accuracy: 0.5919 - val_loss: 39.9666\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 27.4243 - val_accuracy: 0.5919 - val_loss: 33.8845\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5865 - loss: 26.3965 - val_accuracy: 0.5874 - val_loss: 23.0389\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5679 - loss: 24.6416 - val_accuracy: 0.5919 - val_loss: 22.9295\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5858 - loss: 18.8212 - val_accuracy: 0.5919 - val_loss: 26.6205\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5764 - loss: 17.9631 - val_accuracy: 0.5919 - val_loss: 21.3947\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6061 - loss: 15.5563 - val_accuracy: 0.5919 - val_loss: 25.3488\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5789 - loss: 16.2727 - val_accuracy: 0.6188 - val_loss: 22.4891\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5977 - loss: 13.8968 - val_accuracy: 0.6323 - val_loss: 15.2581\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5866 - loss: 13.4077 - val_accuracy: 0.4439 - val_loss: 22.9767\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6323 - loss: 10.7676 - val_accuracy: 0.4081 - val_loss: 32.9281\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5647 - loss: 10.4745 - val_accuracy: 0.4798 - val_loss: 21.2005\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5823 - loss: 7.8104 - val_accuracy: 0.5561 - val_loss: 11.9932\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5677 - loss: 9.7907 - val_accuracy: 0.6233 - val_loss: 3.9418\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 6.5486 - val_accuracy: 0.5336 - val_loss: 3.7076\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6234 - loss: 5.5449 - val_accuracy: 0.6413 - val_loss: 1.5593\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6201 - loss: 1.4883 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5312 - loss: 21.1445 - val_accuracy: 0.5874 - val_loss: 8.7414\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5833 - loss: 9.2861 - val_accuracy: 0.4126 - val_loss: 4.4727\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5425 - loss: 8.4031 - val_accuracy: 0.3767 - val_loss: 10.4727\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5751 - loss: 6.6635 - val_accuracy: 0.4081 - val_loss: 11.7902\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6107 - loss: 5.7465 - val_accuracy: 0.5381 - val_loss: 3.0153\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6215 - loss: 4.1322 - val_accuracy: 0.4036 - val_loss: 8.7887\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6066 - loss: 3.7494 - val_accuracy: 0.3991 - val_loss: 3.5414\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6241 - loss: 2.9564 - val_accuracy: 0.4350 - val_loss: 1.7276\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5834 - loss: 2.4609 - val_accuracy: 0.4126 - val_loss: 4.1003\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6171 - loss: 2.3876 - val_accuracy: 0.4126 - val_loss: 3.9114\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5973 - loss: 2.1738 - val_accuracy: 0.4081 - val_loss: 3.8200\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6254 - loss: 1.8413 - val_accuracy: 0.4126 - val_loss: 4.4890\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 1.7298 - val_accuracy: 0.4081 - val_loss: 1.6990\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5823 - loss: 1.6648 - val_accuracy: 0.4081 - val_loss: 2.6587\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5869 - loss: 1.4470 - val_accuracy: 0.4081 - val_loss: 3.3511\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5875 - loss: 1.4575 - val_accuracy: 0.4081 - val_loss: 2.1196\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 1.1770 - val_accuracy: 0.4170 - val_loss: 1.2434\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5798 - loss: 1.1342 - val_accuracy: 0.4170 - val_loss: 1.3393\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5747 - loss: 1.2168 - val_accuracy: 0.4081 - val_loss: 1.5419\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5836 - loss: 1.2015 - val_accuracy: 0.4081 - val_loss: 1.7995\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4088 - loss: 1.8088 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5854 - loss: 8.4864 - val_accuracy: 0.5874 - val_loss: 2.1577\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5537 - loss: 2.6659 - val_accuracy: 0.5874 - val_loss: 1.4870\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5477 - loss: 2.0398 - val_accuracy: 0.6009 - val_loss: 0.8548\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4772 - loss: 1.8658 - val_accuracy: 0.5919 - val_loss: 1.4811\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5326 - loss: 1.6712 - val_accuracy: 0.5919 - val_loss: 1.5607\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5649 - loss: 1.3085 - val_accuracy: 0.5919 - val_loss: 1.9856\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5854 - loss: 1.1857 - val_accuracy: 0.5964 - val_loss: 1.4360\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5491 - loss: 1.1054 - val_accuracy: 0.5919 - val_loss: 1.6084\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5953 - loss: 1.0157 - val_accuracy: 0.5919 - val_loss: 1.4272\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5804 - loss: 0.9523 - val_accuracy: 0.6009 - val_loss: 1.1374\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5716 - loss: 0.8959 - val_accuracy: 0.5919 - val_loss: 1.1492\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5679 - loss: 0.9110 - val_accuracy: 0.6009 - val_loss: 1.2076\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5685 - loss: 0.8456 - val_accuracy: 0.5919 - val_loss: 1.1449\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5926 - loss: 0.8320 - val_accuracy: 0.6009 - val_loss: 0.9576\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5764 - loss: 0.8955 - val_accuracy: 0.5919 - val_loss: 0.9128\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5988 - loss: 0.7993 - val_accuracy: 0.5964 - val_loss: 1.0838\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6375 - loss: 0.7907 - val_accuracy: 0.5874 - val_loss: 0.9855\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6083 - loss: 0.7315 - val_accuracy: 0.5964 - val_loss: 0.8556\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5895 - loss: 0.7446 - val_accuracy: 0.6143 - val_loss: 0.8056\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5970 - loss: 0.7865 - val_accuracy: 0.5919 - val_loss: 0.8172\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5870 - loss: 0.8395 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6099 - loss: 68.1328 - val_accuracy: 0.5830 - val_loss: 33.2970\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5698 - loss: 45.3037 - val_accuracy: 0.4619 - val_loss: 47.1671\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6035 - loss: 29.6375 - val_accuracy: 0.6368 - val_loss: 6.6352\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5593 - loss: 24.8136 - val_accuracy: 0.5874 - val_loss: 8.9756\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5490 - loss: 22.4829 - val_accuracy: 0.3991 - val_loss: 14.4242\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5876 - loss: 22.0629 - val_accuracy: 0.6009 - val_loss: 9.8843\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6088 - loss: 17.4958 - val_accuracy: 0.5157 - val_loss: 16.0638\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5599 - loss: 19.3885 - val_accuracy: 0.5426 - val_loss: 12.3453\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5678 - loss: 21.1618 - val_accuracy: 0.6143 - val_loss: 11.1508\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5978 - loss: 13.6295 - val_accuracy: 0.6054 - val_loss: 10.0430\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5956 - loss: 14.2737 - val_accuracy: 0.5919 - val_loss: 14.8229\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 11.9265 - val_accuracy: 0.6009 - val_loss: 10.1425\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6117 - loss: 10.0509 - val_accuracy: 0.6188 - val_loss: 7.2751\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5908 - loss: 13.4589 - val_accuracy: 0.4350 - val_loss: 15.8024\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5831 - loss: 12.9842 - val_accuracy: 0.6188 - val_loss: 8.4937\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5603 - loss: 8.4542 - val_accuracy: 0.6188 - val_loss: 4.9710\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6253 - loss: 6.9510 - val_accuracy: 0.6368 - val_loss: 5.7624\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5974 - loss: 7.4783 - val_accuracy: 0.6009 - val_loss: 11.8551\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5839 - loss: 11.6380 - val_accuracy: 0.6323 - val_loss: 3.9108\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5775 - loss: 9.7442 - val_accuracy: 0.6233 - val_loss: 6.7637\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6329 - loss: 6.4492 \n",
      "Training model with: layers = 3, dropout = 0.2, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4971 - loss: 35.4455 - val_accuracy: 0.4126 - val_loss: 12.9884\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5578 - loss: 11.0423 - val_accuracy: 0.4126 - val_loss: 2.8919\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5645 - loss: 8.9290 - val_accuracy: 0.6099 - val_loss: 1.2739\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5294 - loss: 7.3578 - val_accuracy: 0.6099 - val_loss: 1.5181\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5478 - loss: 6.5043 - val_accuracy: 0.4081 - val_loss: 11.3995\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5673 - loss: 4.9802 - val_accuracy: 0.4081 - val_loss: 10.3039\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5725 - loss: 4.4164 - val_accuracy: 0.4081 - val_loss: 6.2774\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5522 - loss: 4.5935 - val_accuracy: 0.4126 - val_loss: 6.9077\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5823 - loss: 3.7414 - val_accuracy: 0.4126 - val_loss: 6.0558\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5612 - loss: 3.2800 - val_accuracy: 0.4305 - val_loss: 2.6900\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 3.6188 - val_accuracy: 0.4036 - val_loss: 4.2692\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5433 - loss: 3.0386 - val_accuracy: 0.4081 - val_loss: 4.6732\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5630 - loss: 2.5100 - val_accuracy: 0.4170 - val_loss: 3.6628\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5718 - loss: 2.3044 - val_accuracy: 0.4081 - val_loss: 1.9150\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5991 - loss: 2.0389 - val_accuracy: 0.5964 - val_loss: 1.0755\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6111 - loss: 1.8729 - val_accuracy: 0.4215 - val_loss: 2.2503\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6098 - loss: 1.9210 - val_accuracy: 0.4395 - val_loss: 2.2527\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5752 - loss: 1.7062 - val_accuracy: 0.6233 - val_loss: 0.8347\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5934 - loss: 1.4325 - val_accuracy: 0.4260 - val_loss: 1.2706\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5783 - loss: 1.4997 - val_accuracy: 0.6054 - val_loss: 1.5513\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6186 - loss: 1.3080 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4807 - loss: 9.2842 - val_accuracy: 0.5919 - val_loss: 2.1391\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5320 - loss: 3.8705 - val_accuracy: 0.6054 - val_loss: 0.7783\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5586 - loss: 2.5751 - val_accuracy: 0.6054 - val_loss: 0.6871\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6151 - loss: 1.9844 - val_accuracy: 0.5964 - val_loss: 1.3453\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5732 - loss: 1.7924 - val_accuracy: 0.5919 - val_loss: 0.7450\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5122 - loss: 1.7092 - val_accuracy: 0.5919 - val_loss: 1.3883\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5857 - loss: 1.3407 - val_accuracy: 0.5919 - val_loss: 1.1876\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5616 - loss: 1.3844 - val_accuracy: 0.6413 - val_loss: 0.7976\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5901 - loss: 1.1841 - val_accuracy: 0.5919 - val_loss: 0.7215\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5722 - loss: 1.0149 - val_accuracy: 0.5919 - val_loss: 0.8150\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5566 - loss: 1.1423 - val_accuracy: 0.5919 - val_loss: 0.8542\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6059 - loss: 0.9197 - val_accuracy: 0.5919 - val_loss: 0.9624\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5827 - loss: 0.8835 - val_accuracy: 0.5919 - val_loss: 0.8000\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5910 - loss: 0.8440 - val_accuracy: 0.5919 - val_loss: 0.9022\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5727 - loss: 0.8640 - val_accuracy: 0.5919 - val_loss: 0.8909\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5683 - loss: 0.8751 - val_accuracy: 0.5919 - val_loss: 0.8644\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5780 - loss: 0.7937 - val_accuracy: 0.5919 - val_loss: 0.7422\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6125 - loss: 0.7572 - val_accuracy: 0.5919 - val_loss: 0.6719\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6015 - loss: 0.7354 - val_accuracy: 0.5964 - val_loss: 0.6920\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5685 - loss: 0.7681 - val_accuracy: 0.5919 - val_loss: 0.7172\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5829 - loss: 0.7255 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4221 - loss: 3145.3699 - val_accuracy: 0.5919 - val_loss: 497.7764\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6295 - loss: 303.2120 - val_accuracy: 0.4126 - val_loss: 363.2068\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5553 - loss: 145.4171 - val_accuracy: 0.5830 - val_loss: 23.0344\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5695 - loss: 116.8173 - val_accuracy: 0.5919 - val_loss: 81.8428\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 98.5608 - val_accuracy: 0.5919 - val_loss: 47.3575\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5206 - loss: 93.8503 - val_accuracy: 0.5919 - val_loss: 74.5639\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5885 - loss: 68.5313 - val_accuracy: 0.5919 - val_loss: 79.9852\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5792 - loss: 62.8966 - val_accuracy: 0.5919 - val_loss: 77.0313\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 59.8422 - val_accuracy: 0.5919 - val_loss: 83.0155\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5904 - loss: 43.1762 - val_accuracy: 0.5874 - val_loss: 48.0143\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5752 - loss: 49.6308 - val_accuracy: 0.6009 - val_loss: 49.7076\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 48.6397 - val_accuracy: 0.5964 - val_loss: 42.7280\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5766 - loss: 37.2690 - val_accuracy: 0.6143 - val_loss: 36.1660\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5557 - loss: 31.1926 - val_accuracy: 0.5919 - val_loss: 40.2588\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5951 - loss: 27.7957 - val_accuracy: 0.5919 - val_loss: 42.1731\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5727 - loss: 28.1705 - val_accuracy: 0.6009 - val_loss: 26.8238\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6001 - loss: 22.3717 - val_accuracy: 0.5919 - val_loss: 31.4343\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5878 - loss: 27.2343 - val_accuracy: 0.6099 - val_loss: 21.9438\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5917 - loss: 19.7824 - val_accuracy: 0.5919 - val_loss: 24.6528\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5547 - loss: 20.0090 - val_accuracy: 0.6009 - val_loss: 18.0979\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5980 - loss: 17.3390 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5025 - loss: 51.3424 - val_accuracy: 0.5874 - val_loss: 18.8801\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5443 - loss: 31.2317 - val_accuracy: 0.6009 - val_loss: 4.6064\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6078 - loss: 20.1783 - val_accuracy: 0.4081 - val_loss: 13.6426\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5481 - loss: 17.2765 - val_accuracy: 0.4081 - val_loss: 17.6456\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5742 - loss: 12.7148 - val_accuracy: 0.4170 - val_loss: 9.8734\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5803 - loss: 14.2040 - val_accuracy: 0.4170 - val_loss: 11.6957\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5689 - loss: 11.6428 - val_accuracy: 0.4081 - val_loss: 18.6463\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5556 - loss: 9.9920 - val_accuracy: 0.4126 - val_loss: 9.1786\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6109 - loss: 7.8596 - val_accuracy: 0.4081 - val_loss: 13.0307\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5928 - loss: 7.7070 - val_accuracy: 0.4170 - val_loss: 11.1193\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5728 - loss: 6.5298 - val_accuracy: 0.4305 - val_loss: 8.0137\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5678 - loss: 7.4810 - val_accuracy: 0.4260 - val_loss: 7.3620\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5819 - loss: 6.2921 - val_accuracy: 0.4529 - val_loss: 6.0068\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5691 - loss: 5.3084 - val_accuracy: 0.6143 - val_loss: 3.5728\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5686 - loss: 4.3251 - val_accuracy: 0.6143 - val_loss: 2.7665\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6477 - loss: 3.7289 - val_accuracy: 0.6188 - val_loss: 1.7489\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6437 - loss: 3.5546 - val_accuracy: 0.6233 - val_loss: 1.3539\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6070 - loss: 4.1278 - val_accuracy: 0.6323 - val_loss: 0.9532\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5582 - loss: 3.1410 - val_accuracy: 0.6009 - val_loss: 1.6175\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6088 - loss: 2.8331 - val_accuracy: 0.5964 - val_loss: 1.4459\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5996 - loss: 1.6293 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.0005, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5354 - loss: 11.6526 - val_accuracy: 0.5874 - val_loss: 2.8271\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5154 - loss: 4.4930 - val_accuracy: 0.5874 - val_loss: 2.0710\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5422 - loss: 3.5925 - val_accuracy: 0.5919 - val_loss: 4.0303\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5425 - loss: 3.0494 - val_accuracy: 0.5919 - val_loss: 3.1841\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5653 - loss: 2.0940 - val_accuracy: 0.5919 - val_loss: 2.5776\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5444 - loss: 1.9253 - val_accuracy: 0.5919 - val_loss: 2.2709\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5584 - loss: 1.7505 - val_accuracy: 0.5874 - val_loss: 1.4805\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5427 - loss: 1.5421 - val_accuracy: 0.5919 - val_loss: 1.8282\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5380 - loss: 1.3193 - val_accuracy: 0.5919 - val_loss: 1.9244\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5842 - loss: 1.0838 - val_accuracy: 0.5919 - val_loss: 1.4014\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6057 - loss: 1.0843 - val_accuracy: 0.5874 - val_loss: 1.3559\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5665 - loss: 1.0297 - val_accuracy: 0.5919 - val_loss: 1.4961\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5827 - loss: 1.1391 - val_accuracy: 0.5919 - val_loss: 1.1318\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5858 - loss: 0.9860 - val_accuracy: 0.5919 - val_loss: 0.8178\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5623 - loss: 0.9277 - val_accuracy: 0.5919 - val_loss: 1.0634\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5556 - loss: 0.9432 - val_accuracy: 0.5919 - val_loss: 0.9118\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5703 - loss: 0.8602 - val_accuracy: 0.5919 - val_loss: 0.7615\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5915 - loss: 0.7669 - val_accuracy: 0.5919 - val_loss: 0.7405\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5846 - loss: 0.7902 - val_accuracy: 0.5874 - val_loss: 0.7079\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5770 - loss: 0.7464 - val_accuracy: 0.5874 - val_loss: 0.7440\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5781 - loss: 0.7571 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.0005, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4574 - loss: 1156.4130 - val_accuracy: 0.5919 - val_loss: 316.6465\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5738 - loss: 168.6047 - val_accuracy: 0.5919 - val_loss: 175.1247\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 117.9272 - val_accuracy: 0.5919 - val_loss: 98.1777\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5801 - loss: 87.9670 - val_accuracy: 0.5919 - val_loss: 77.1097\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5488 - loss: 83.5319 - val_accuracy: 0.5919 - val_loss: 78.8048\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5839 - loss: 60.8683 - val_accuracy: 0.5919 - val_loss: 83.4156\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 60.4563 - val_accuracy: 0.5919 - val_loss: 55.9535\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5574 - loss: 57.7443 - val_accuracy: 0.5919 - val_loss: 66.6841\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5946 - loss: 39.8016 - val_accuracy: 0.5919 - val_loss: 63.3314\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 37.7378 - val_accuracy: 0.6054 - val_loss: 25.7721\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 43.0287 - val_accuracy: 0.5964 - val_loss: 37.2984\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5983 - loss: 32.4209 - val_accuracy: 0.5964 - val_loss: 14.9105\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5986 - loss: 27.3478 - val_accuracy: 0.6099 - val_loss: 18.5453\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6331 - loss: 19.2907 - val_accuracy: 0.6143 - val_loss: 12.7823\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5475 - loss: 18.9235 - val_accuracy: 0.6188 - val_loss: 7.4027\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5560 - loss: 21.2767 - val_accuracy: 0.6143 - val_loss: 3.6065\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5910 - loss: 18.6341 - val_accuracy: 0.6188 - val_loss: 2.3917\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5553 - loss: 12.4894 - val_accuracy: 0.6099 - val_loss: 2.4200\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5706 - loss: 12.6777 - val_accuracy: 0.5919 - val_loss: 5.2300\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5861 - loss: 11.0410 - val_accuracy: 0.6099 - val_loss: 2.1991\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5978 - loss: 1.7612 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.0005, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5935 - loss: 57.2648 - val_accuracy: 0.5919 - val_loss: 18.3250\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5567 - loss: 15.2169 - val_accuracy: 0.5874 - val_loss: 9.6182\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5260 - loss: 12.9732 - val_accuracy: 0.5964 - val_loss: 3.8984\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5834 - loss: 10.0973 - val_accuracy: 0.6368 - val_loss: 2.4350\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 7.6585 - val_accuracy: 0.5067 - val_loss: 3.1848\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6165 - loss: 7.1886 - val_accuracy: 0.6547 - val_loss: 1.7795\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5907 - loss: 7.4851 - val_accuracy: 0.4170 - val_loss: 4.1130\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6191 - loss: 4.5826 - val_accuracy: 0.4081 - val_loss: 9.2382\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5849 - loss: 4.9375 - val_accuracy: 0.4081 - val_loss: 7.0303\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5831 - loss: 4.5374 - val_accuracy: 0.4170 - val_loss: 5.9392\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5847 - loss: 3.8003 - val_accuracy: 0.4126 - val_loss: 3.2045\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6023 - loss: 3.0871 - val_accuracy: 0.4126 - val_loss: 2.1944\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 2.3310 - val_accuracy: 0.4215 - val_loss: 1.0023\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5937 - loss: 2.4030 - val_accuracy: 0.4260 - val_loss: 0.8802\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5821 - loss: 2.1122 - val_accuracy: 0.4126 - val_loss: 0.8329\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5971 - loss: 2.1854 - val_accuracy: 0.4215 - val_loss: 0.8251\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6261 - loss: 1.5604 - val_accuracy: 0.4395 - val_loss: 1.1136\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6177 - loss: 1.5021 - val_accuracy: 0.4126 - val_loss: 1.2113\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5888 - loss: 1.3421 - val_accuracy: 0.4170 - val_loss: 0.8110\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5980 - loss: 1.3087 - val_accuracy: 0.4170 - val_loss: 0.7921\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4106 - loss: 0.7945 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.0001, pooling = avg\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5434 - loss: 11.7774 - val_accuracy: 0.6099 - val_loss: 2.2479\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5117 - loss: 5.4153 - val_accuracy: 0.5919 - val_loss: 7.0208\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5405 - loss: 4.6547 - val_accuracy: 0.6054 - val_loss: 2.9947\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5446 - loss: 3.5346 - val_accuracy: 0.5919 - val_loss: 3.3280\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5673 - loss: 3.1119 - val_accuracy: 0.5919 - val_loss: 2.6990\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5815 - loss: 2.3562 - val_accuracy: 0.6099 - val_loss: 1.0042\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5798 - loss: 1.9745 - val_accuracy: 0.5740 - val_loss: 0.9787\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5964 - loss: 1.8736 - val_accuracy: 0.5964 - val_loss: 1.0780\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5636 - loss: 1.8252 - val_accuracy: 0.6009 - val_loss: 1.5640\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6135 - loss: 1.3340 - val_accuracy: 0.6009 - val_loss: 1.5372\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5322 - loss: 1.4414 - val_accuracy: 0.6143 - val_loss: 0.8991\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5606 - loss: 1.2026 - val_accuracy: 0.6143 - val_loss: 0.9470\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5609 - loss: 1.1858 - val_accuracy: 0.6054 - val_loss: 0.9578\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5643 - loss: 1.2823 - val_accuracy: 0.6099 - val_loss: 0.9106\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5486 - loss: 1.0723 - val_accuracy: 0.6099 - val_loss: 0.8312\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5816 - loss: 0.9993 - val_accuracy: 0.6233 - val_loss: 0.7774\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5723 - loss: 0.8986 - val_accuracy: 0.6233 - val_loss: 0.8102\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6081 - loss: 0.8435 - val_accuracy: 0.6054 - val_loss: 0.8194\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6043 - loss: 0.8341 - val_accuracy: 0.6099 - val_loss: 0.7543\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6168 - loss: 0.8703 - val_accuracy: 0.6278 - val_loss: 0.7007\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6175 - loss: 0.6856 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.0001, pooling = sum\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5783 - loss: 260.7144 - val_accuracy: 0.5919 - val_loss: 189.1046\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5914 - loss: 95.5736 - val_accuracy: 0.5919 - val_loss: 106.1646\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5928 - loss: 73.5398 - val_accuracy: 0.5919 - val_loss: 88.5228\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5757 - loss: 73.6068 - val_accuracy: 0.5919 - val_loss: 67.2839\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6209 - loss: 47.8228 - val_accuracy: 0.5919 - val_loss: 47.1925\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5861 - loss: 42.1654 - val_accuracy: 0.5919 - val_loss: 28.6026\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6134 - loss: 26.5237 - val_accuracy: 0.5919 - val_loss: 45.6465\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5795 - loss: 29.0380 - val_accuracy: 0.6099 - val_loss: 16.2666\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5945 - loss: 18.6771 - val_accuracy: 0.5650 - val_loss: 10.6533\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5847 - loss: 15.7587 - val_accuracy: 0.3857 - val_loss: 28.1714\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5808 - loss: 13.4485 - val_accuracy: 0.4170 - val_loss: 28.4459\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5604 - loss: 10.4957 - val_accuracy: 0.5336 - val_loss: 8.0638\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5884 - loss: 9.4112 - val_accuracy: 0.4126 - val_loss: 13.2122\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6135 - loss: 7.8943 - val_accuracy: 0.6099 - val_loss: 5.5557\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5715 - loss: 6.5967 - val_accuracy: 0.5740 - val_loss: 3.9957\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5802 - loss: 5.2494 - val_accuracy: 0.4170 - val_loss: 6.8770\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5623 - loss: 5.2589 - val_accuracy: 0.5291 - val_loss: 1.2162\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6021 - loss: 4.2520 - val_accuracy: 0.6637 - val_loss: 0.8601\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5975 - loss: 7.9503 - val_accuracy: 0.5067 - val_loss: 1.0233\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5641 - loss: 3.8221 - val_accuracy: 0.6771 - val_loss: 0.7560\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6855 - loss: 0.8889 \n",
      "Training model with: layers = 3, dropout = 0.3, lr = 0.0001, pooling = max\n",
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5519 - loss: 46.3491 - val_accuracy: 0.5919 - val_loss: 7.0050\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5766 - loss: 12.3571 - val_accuracy: 0.4260 - val_loss: 2.8301\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5377 - loss: 8.8550 - val_accuracy: 0.4081 - val_loss: 9.5905\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5538 - loss: 8.0208 - val_accuracy: 0.4215 - val_loss: 4.3622\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5882 - loss: 5.4589 - val_accuracy: 0.4215 - val_loss: 4.1869\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5996 - loss: 4.9810 - val_accuracy: 0.4126 - val_loss: 6.2315\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5532 - loss: 5.0197 - val_accuracy: 0.4081 - val_loss: 8.2872\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5619 - loss: 3.5456 - val_accuracy: 0.4081 - val_loss: 9.3080\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6132 - loss: 3.9874 - val_accuracy: 0.4170 - val_loss: 5.8545\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5945 - loss: 2.8280 - val_accuracy: 0.4170 - val_loss: 5.5291\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5629 - loss: 2.3876 - val_accuracy: 0.4170 - val_loss: 3.8158\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6322 - loss: 1.7079 - val_accuracy: 0.4126 - val_loss: 3.0669\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 1.8354 - val_accuracy: 0.4126 - val_loss: 3.3564\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6004 - loss: 1.8279 - val_accuracy: 0.4081 - val_loss: 2.2388\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5960 - loss: 1.6113 - val_accuracy: 0.4081 - val_loss: 2.1749\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6212 - loss: 1.5766 - val_accuracy: 0.4081 - val_loss: 1.2356\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5953 - loss: 1.3523 - val_accuracy: 0.4170 - val_loss: 2.1260\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5873 - loss: 1.4399 - val_accuracy: 0.4170 - val_loss: 2.1358\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6139 - loss: 1.4326 - val_accuracy: 0.4170 - val_loss: 1.6716\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6359 - loss: 1.1265 - val_accuracy: 0.4170 - val_loss: 1.3479\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4112 - loss: 1.1705 \n"
     ]
    }
   ],
   "source": [
    "# train model using hyperparams \n",
    "results = []\n",
    "\n",
    "for num_layers, dropout_rates, learning_rates, pooling_var in param_grid:\n",
    "    print(f\"Training model with: layers = {num_layers}, dropout = {dropout_rates}, lr = {learning_rates}, pooling = {pooling_var}\")\n",
    "    \n",
    "    model=build_gcn_model(num_layers, dropout_rates, pooling_var, learning_rates, input_shape, num_classes)\n",
    "    \n",
    "    history = model.fit(\n",
    "    train_loader.load(),\n",
    "    steps_per_epoch=train_loader.steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=test_loader.load(),\n",
    "    validation_steps=test_loader.steps_per_epoch\n",
    "    )\n",
    "\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(\n",
    "    test_loader.load(),\n",
    "    steps=test_loader.steps_per_epoch,\n",
    "    verbose=1\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'num_layers': num_layers,\n",
    "        'dropout_rate': dropout_rates,\n",
    "        'learning_rate': learning_rates,\n",
    "        'pooling variants': pooling_var,\n",
    "        'test_accuracy': test_accuracy\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c67f3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp_results = pd.DataFrame(results)\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "for i, param in enumerate(['num_layers', \n",
    "                           'dropout_rate', \n",
    "                           'learning_rate',\n",
    "                           'pooling variants']):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    sns.boxplot(x=param, y='test_accuracy', data=hp_results)\n",
    "    plt.title(f\"accuracy by {param}\")\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23666b0e",
   "metadata": {},
   "source": [
    "1 layer, dropout rate of 0.1, learning rate of 0.0005, and avg pooling performed the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee7e9ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['node_features', 'adjacency_matrix', 'graph_index']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4154 - loss: 7.2092\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4247 - loss: 1.5041\n",
      "Epoch 3/20\n",
      "\u001b[1m 1/28\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.9193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peytonhall/miniconda3/envs/qbio_490_pbhall/lib/python3.9/site-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'SubsetDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6023 - loss: 0.8383\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5915 - loss: 0.7706\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.7581\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6091 - loss: 0.7207\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.7326\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5989 - loss: 0.7349\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.6782\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 0.7186\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 0.6944\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6364 - loss: 0.6827\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6244 - loss: 0.6994\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 0.6856\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.6903\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.6856\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6401 - loss: 0.7077\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6545 - loss: 0.6587\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6379 - loss: 0.6611\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6352 - loss: 0.6959\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6677 - loss: 0.6479 \n",
      "Final test loss: 0.678\n",
      "Final test accuracy: 0.650\n"
     ]
    }
   ],
   "source": [
    "# train best model on full training data\n",
    "\n",
    "best_model = build_gcn_model(1, 0.1, 'avg', 0.0005, 4, 2)\n",
    "\n",
    "best_model.fit(\n",
    "    train_loader.load(),\n",
    "    steps_per_epoch=train_loader.steps_per_epoch,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "best_loss, best_accuracy = best_model.evaluate(\n",
    "    test_loader.load(),\n",
    "    steps=test_loader.steps_per_epoch)\n",
    "\n",
    "print(f\"Final test loss: {best_loss:.3f}\")\n",
    "print(f\"Final test accuracy: {best_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0a57c",
   "metadata": {},
   "source": [
    "I think the number of GCN layers had the most significant impact on model performancy. Comparing the effects of different pooling methods, GlobalAvgPool seems to be the most robust. This suggests that averaging node representations could provide a more balanced summary of graph structure than other poolong methods. Regarding performance, the test loss decreased from 0.792 to 0.678 and the final test accuracy increased from 0.623 to 0.650. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
